{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 65711,
          "databundleVersionId": 7405009,
          "sourceType": "competition"
        },
        {
          "sourceId": 5536933,
          "sourceType": "datasetVersion",
          "datasetId": 3191230
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "üè¶ Bank Customer Churn üìâ EDA + Business Analysis",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "shubhammeshram579_bank_customer_churn_prediction_path = kagglehub.dataset_download('shubhammeshram579/bank-customer-churn-prediction')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CD6OeBva4-q3",
        "outputId": "c262bdb1-536e-4f4b-aaf9-7d13b0749103",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shubhammeshram579/bank-customer-churn-prediction?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 262k/262k [00:00<00:00, 33.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Google Fonts -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        üè¶ Bank Customer Churn üìâ\n",
        "    </h1>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "tDbZOtmK4-q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÇ Overview\n",
        "\n",
        "* **Background** <br>\n",
        "Every bank wants to hold there customers for sustaining their business. Understanding the reasons why customers leave will help banks improve retention policies and reduce costs.\n",
        "\n",
        "* **Goal of the Project** <br>\n",
        "Based on the data, we will find out what causes customers to leave and then come up with appropriate strategies to help the bank.\n",
        "\n",
        "**Key Features**\n",
        "\n",
        "**Target Variable** <br>\n",
        "- `Exited`: *whether or not the customer left the bank.*\n",
        "\n",
        "**General Property Characteristics** <br>\n",
        "- `RowNumber`: Corresponds to the record (row) number and has no effect on the output.\n",
        "- `CustomerId`: Contains random values and has no effect on customer leaving the bank.\n",
        "- `Surname`: The surname of a customer has no impact on their decision to leave the bank.\n",
        "- `CreditScore`: can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n",
        "- `Geography`: A customer‚Äôs location can affect their decision to leave the bank.\n",
        "- `Gender`: It‚Äôs interesting to explore whether gender plays a role in a customer leaving the bank.\n",
        "- `Age`: This is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n",
        "- `Tenure`: Refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n",
        "- `Balance`: Also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n",
        "- `NumOfProducts`: Refers to the number of products that a customer has purchased through the bank.\n",
        "- `HasCrCard`: Denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n",
        "- `IsActiveMember`: Active customers are less likely to leave the bank.\n",
        "- `EstimatedSalary`: As with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n",
        "\n",
        "**Files Provided**\n",
        "\n",
        "* `train.csv`: The train dataset.\n",
        "* `test.csv`: The test dataset (no target).\n",
        "* `credit_risk_dataset.csv`: The original dataset.\n",
        "\n",
        "Source: [Binary Classification with a Bank Churn Dataset](https://www.kaggle.com/competitions/playground-series-s4e1)\n",
        "\n",
        "Source: [Bank Customer Churn Prediction](https://www.kaggle.com/datasets/shubhammeshram579/bank-customer-churn-prediction)\n",
        "\n",
        "**Project Objective**\n",
        "\n",
        "The primary objective of this notebook is to **EDA and build machine learning model to predict**.\n",
        "\n",
        "Key components of the approach include:\n",
        "\n",
        "* **Exploratory Data Analysis (EDA):** Understand feature distributions, relationships.\n",
        "* **Feature Engineering:** Encode categorical variables and align schema across training and test data.\n",
        "* **Modeling:** Train with some models and choise the best model for predicting.\n",
        "* **Multi-Label Prediction Strategy:** Generate predictions for each test row.\n",
        "* **Evaluation Framework:** <br>\n",
        "  * Cross-validation.\n",
        "  * Metrics: ROC-AUC"
      ],
      "metadata": {
        "id": "7WdWZhsG4-q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels > pip_log_statsmodels.txt 2>&1\n",
        "!pip install scikit_posthocs > pip_log_scikit_posthocs.txt 2>&1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:10.826514Z",
          "iopub.execute_input": "2025-08-12T10:18:10.827178Z",
          "iopub.status.idle": "2025-08-12T10:18:18.107069Z",
          "shell.execute_reply.started": "2025-08-12T10:18:10.827149Z",
          "shell.execute_reply": "2025-08-12T10:18:18.105879Z"
        },
        "id": "bQV43BP94-q6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Import Libraries</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Import Libraries\n",
        "    </h1>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "d-lAHEzz4-q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "# Statistical functions\n",
        "from scipy.stats import skew\n",
        "\n",
        "# Display utilities for Jupyter notebooks\n",
        "from IPython.display import display\n",
        "\n",
        "# Machine learning preprocessing and modeling\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, classification_report, confusion_matrix,\n",
        "                             precision_recall_curve, auc)\n",
        "\n",
        "# Statistical\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import shapiro, probplot\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import levene\n",
        "from scipy.stats import ttest_ind\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from scipy.stats import kruskal\n",
        "from scipy.stats import anderson\n",
        "from scipy.stats import normaltest\n",
        "import scikit_posthocs as sp\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 500) # To display all the columns of dataframe\n",
        "pd.set_option(\"max_colwidth\", None) # To set the width of the column to maximum"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:18.108411Z",
          "iopub.execute_input": "2025-08-12T10:18:18.108686Z",
          "iopub.status.idle": "2025-08-12T10:18:22.153915Z",
          "shell.execute_reply.started": "2025-08-12T10:18:18.108659Z",
          "shell.execute_reply": "2025-08-12T10:18:22.152808Z"
        },
        "trusted": true,
        "id": "QRGtUoeb4-q7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Load Data</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Load Data\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "vz3TEXXA4-q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "df_train = pd.read_csv(\"/kaggle/input/playground-series-s4e1/train.csv\")\n",
        "df_origin = pd.read_csv(\"/kaggle/input/bank-customer-churn-prediction/Churn_Modelling.csv\")\n",
        "df_test = pd.read_csv(\"/kaggle/input/playground-series-s4e1/test.csv\")\n",
        "\n",
        "# Verify shapes\n",
        "print(\"Train Data Shape:\", df_train.shape)\n",
        "print(\"\\nOrigin Data Shape:\", df_origin.shape)\n",
        "print(\"\\nTest Data Shape:\", df_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.154957Z",
          "iopub.execute_input": "2025-08-12T10:18:22.155585Z",
          "iopub.status.idle": "2025-08-12T10:18:22.576606Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.155553Z",
          "shell.execute_reply": "2025-08-12T10:18:22.575025Z"
        },
        "trusted": true,
        "id": "E9gTh8JF4-q9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Data Preview and Info</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Data Preview and Info\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "rV6EqF8G4-q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display few rows of each dataset\n",
        "print(\"Train Data Preview:\")\n",
        "display(df_train.head())\n",
        "\n",
        "print(\"\\nOrigin Data Preview:\")\n",
        "display(df_origin.head())\n",
        "\n",
        "print(\"\\nTest Data Preview:\")\n",
        "display(df_test.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.577722Z",
          "iopub.execute_input": "2025-08-12T10:18:22.578102Z",
          "iopub.status.idle": "2025-08-12T10:18:22.627952Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.578067Z",
          "shell.execute_reply": "2025-08-12T10:18:22.626674Z"
        },
        "trusted": true,
        "id": "ID7wk_NR4-q-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the DataFrames\n",
        "print(\"Train Data Info:\")\n",
        "df_train.info()\n",
        "\n",
        "print(\"\\nOrigin Data Info:\")\n",
        "df_origin.info()\n",
        "\n",
        "print(\"\\nTest Data Info:\")\n",
        "df_test.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.629036Z",
          "iopub.execute_input": "2025-08-12T10:18:22.629402Z",
          "iopub.status.idle": "2025-08-12T10:18:22.69394Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.629339Z",
          "shell.execute_reply": "2025-08-12T10:18:22.692986Z"
        },
        "trusted": true,
        "id": "OfjVCEEF4-q-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insights from Initial Data Exploration\n",
        "\n",
        "**Dataset Size and Structure**\n",
        "   - The **training dataset** contains 165034 samples with 14 columns, including the target variable `Exited`.\n",
        "   - The **original dataset** has 10002 samples and 14 columns, similar in structure but smaller in size.\n",
        "   - The **test dataset** includes 110023 samples with 13 columns (without the target), ready for prediction.\n",
        "\n",
        "**Feature Overview**  \n",
        "   - Both datasets include all important attributes:\n",
        "     - **Numerical features:** `CreditScore`, `Age`, `Tenure`, `Balance`, `EstimatedSalary`, `Points Earned`.\n",
        "     - **Categorical features:** `Geography`, `Gender`, `HasCrCard`, `IsActiveMember`, `Complain`, `Card Type`, `Satisfaction Score`, `NumOfProducts`.\n",
        "   - The target variable is **int64** value but we need to convert to **int8** to save memory usage.\n",
        "\n",
        "**Data Completeness**  \n",
        "   - The dataset have **no missing values** on train and test datasets but the missing value was detected on the origin dataset. We need to handle it.\n",
        "   - Data types are appropriate: numerical features is float64 and int64, and categorical features are objects (strings).\n",
        "   - The columns `Surname`, `RowNumber`, `CustomerId`, `id` are not meaningful for analysis. So these columns are not really a part of the information we should care about. We can drop them."
      ],
      "metadata": {
        "id": "x0to3BC_4-q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns Surname, id and CustomerId\n",
        "df_train.drop(columns=\"Surname\", axis=1, inplace=True)\n",
        "df_train.set_index(df_train.id, inplace=True)\n",
        "df_train.drop(columns=\"id\", axis=1, inplace=True)\n",
        "df_train.drop(columns=\"CustomerId\", axis=1, inplace=True)\n",
        "\n",
        "df_origin.drop(columns=\"Surname\", axis=1, inplace=True)\n",
        "df_origin.set_index(df_origin.RowNumber, inplace=True)\n",
        "df_origin.drop(columns=\"RowNumber\", axis=1, inplace=True)\n",
        "df_origin.drop(columns=\"CustomerId\", axis=1, inplace=True)\n",
        "\n",
        "df_test.drop(columns=\"Surname\", axis=1, inplace=True)\n",
        "df_test.set_index(df_test.id, inplace=True)\n",
        "df_test.drop(columns=\"id\", axis=1, inplace=True)\n",
        "df_test.drop(columns=\"CustomerId\", axis=1, inplace=True)\n",
        "\n",
        "# Remove space in name columns\n",
        "df_train.columns = (\n",
        "    df_train.columns\n",
        "    .str.strip()\n",
        "    .str.replace(\" \", \"\")\n",
        ")\n",
        "\n",
        "df_origin.columns = (\n",
        "    df_origin.columns\n",
        "    .str.strip()\n",
        "    .str.replace(\" \", \"\")\n",
        ")\n",
        "\n",
        "df_test.columns = (\n",
        "    df_test.columns\n",
        "    .str.strip()\n",
        "    .str.replace(\" \", \"\")\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.697045Z",
          "iopub.execute_input": "2025-08-12T10:18:22.697312Z",
          "iopub.status.idle": "2025-08-12T10:18:22.743716Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.697293Z",
          "shell.execute_reply": "2025-08-12T10:18:22.742514Z"
        },
        "trusted": true,
        "id": "-a8CPUhk4-q_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data describe:\")\n",
        "cm = sns.light_palette(\"green\", as_cmap=True)\n",
        "display(df_train.drop(columns=[\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\", \"Exited\"], axis=1).describe().T.style.background_gradient(cmap=cm))\n",
        "display(df_origin.drop(columns=[\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\", \"Exited\"], axis=1).describe().T.style.background_gradient(cmap=cm))\n",
        "display(df_test.drop(columns=[\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\"], axis=1).describe().T.style.background_gradient(cmap=cm))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.744534Z",
          "iopub.execute_input": "2025-08-12T10:18:22.744762Z",
          "iopub.status.idle": "2025-08-12T10:18:22.923969Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.744744Z",
          "shell.execute_reply": "2025-08-12T10:18:22.923145Z"
        },
        "trusted": true,
        "id": "jED0iMqB4-rA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Insights from Dataset Statistics\n",
        "\n",
        "**Feature Highlights**\n",
        "\n",
        "* **CreditScore**: Mean \\~650 (original data) or \\~656 (train and test data), range 350‚Äì850 ‚Üí covers both poor and excellent credit levels; high standard deviation indicates considerable dispersion.\n",
        "* **Age**: Mean \\~38 years, primarily concentrated in the working-age group (25% = 32 years, 75% = 42 or 44 years).\n",
        "* **Tenure**: Average of 5 years, evenly distributed from 0‚Äì10 years ‚Üí reflects diverse customer loyalty levels.\n",
        "* **Balance**: High mean (\\$55k/$76k) but large standard deviation (~\\$62k); 25% of customers have a balance of \\$0 ‚Üí possibly low usage or fully withdrawn accounts.\n",
        "* **EstimatedSalary**: Mean ~\\$100k (original data) or ~\\$113k (train and test data), wide range (\\$11.58 ‚Äì \\$199,992), median close to mean ‚Üí relatively uniform distribution.\n",
        "\n",
        "**Overall Observations**\n",
        "\n",
        "* The three datasets (train, test, origin) have **very similar distributions** in statistical measures (mean, median, min, max, percentiles).\n",
        "* Several features (`Balance`, `EstimatedSalary`, `CreditScore`) show high dispersion ‚Üí further analysis is needed to check for skewness and outliers.\n",
        "* Customers are mostly within the working-age demographic, with an average tenure of 5 years, and exhibit diverse financial behaviors and engagement levels."
      ],
      "metadata": {
        "id": "8Yt0RgwC4-rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = [\"Geography\", \"Gender\"]\n",
        "def convert_cat(df, cat_features= cat_features):\n",
        "    for feature in cat_features:\n",
        "        if feature in df.columns:\n",
        "            df[feature] = df[feature].astype(\"category\")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "convert_cat(df=df_train)\n",
        "convert_cat(df=df_origin)\n",
        "convert_cat(df=df_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.925007Z",
          "iopub.execute_input": "2025-08-12T10:18:22.925398Z",
          "iopub.status.idle": "2025-08-12T10:18:22.970107Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.925351Z",
          "shell.execute_reply": "2025-08-12T10:18:22.969109Z"
        },
        "trusted": true,
        "id": "JEukHf9c4-rA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_origin.dropna(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.971653Z",
          "iopub.execute_input": "2025-08-12T10:18:22.972044Z",
          "iopub.status.idle": "2025-08-12T10:18:22.979555Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.972013Z",
          "shell.execute_reply": "2025-08-12T10:18:22.978737Z"
        },
        "trusted": true,
        "id": "hreUm2am4-rA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def cast_features(dfs, dtype_map):\n",
        "    \"\"\"\n",
        "    Cast multiple features in multiple DataFrames to specific dtypes.\n",
        "\n",
        "    Args:\n",
        "        dfs (list): List of DataFrames to process.\n",
        "        dtype_map (dict): {column_name: target_dtype} mapping.\n",
        "    \"\"\"\n",
        "    for df in dfs:\n",
        "        for col, dtype in dtype_map.items():\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].astype(dtype)\n",
        "\n",
        "# Mapping of columns and their target data types\n",
        "dtype_map = {\n",
        "    \"CreditScore\": \"int16\",\n",
        "    \"Age\": \"int8\",\n",
        "    \"Tenure\": \"int8\",\n",
        "    \"Balance\": \"float32\",\n",
        "    \"Exited\": \"int8\",\n",
        "    \"EstimatedSalary\": \"float32\",\n",
        "    \"HasCrCard\": \"int8\",\n",
        "    \"IsActiveMember\": \"int8\",\n",
        "    \"NumOfProducts\": \"int8\"\n",
        "}\n",
        "\n",
        "# Apply the function to both df_train and df_test\n",
        "cast_features([df_train, df_test, df_origin], dtype_map)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:22.980523Z",
          "iopub.execute_input": "2025-08-12T10:18:22.980877Z",
          "iopub.status.idle": "2025-08-12T10:18:23.013747Z",
          "shell.execute_reply.started": "2025-08-12T10:18:22.980847Z",
          "shell.execute_reply": "2025-08-12T10:18:23.01239Z"
        },
        "trusted": true,
        "id": "_m_BKLXZ4-rB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "category_cols = [\"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\"]\n",
        "df_train[category_cols] = df_train[category_cols].astype(\"category\")\n",
        "df_origin[category_cols] = df_origin[category_cols].astype(\"category\")\n",
        "df_test[category_cols] = df_test[category_cols].astype(\"category\")\n",
        "print(\"Train Data describe:\")\n",
        "display(df_train.drop(columns=\"Exited\", axis=1).describe(include=[\"category\", \"object\"]).T)\n",
        "\n",
        "print(\"\\nOrigin Data describe:\")\n",
        "display(df_origin.drop(columns=\"Exited\", axis=1).describe(include=[\"category\", \"object\"]).T)\n",
        "\n",
        "print(\"\\nTest Data describe:\")\n",
        "display(df_test.describe(include=[\"category\", \"object\"]).T)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.014688Z",
          "iopub.execute_input": "2025-08-12T10:18:23.01504Z",
          "iopub.status.idle": "2025-08-12T10:18:23.102757Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.015015Z",
          "shell.execute_reply": "2025-08-12T10:18:23.10164Z"
        },
        "trusted": true,
        "id": "gQ4f_65-4-rB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descriptive Insights for Categorical Features**\n",
        "\n",
        "**1. Geography**\n",
        "\n",
        "* Contains 3 countries: **France**, **Spain**, and **Germany**.\n",
        "* **France** has the highest proportion in all three datasets (\\~50‚Äì57%), indicating an **uneven distribution** across countries.\n",
        "* Spain and Germany make up the remaining portion with noticeably smaller shares.\n",
        "\n",
        "**2. Gender**\n",
        "\n",
        "* Only 2 values: **Male** and **Female**.\n",
        "* **Male** accounts for a slightly higher proportion (\\~55%) compared to Female (\\~45%) across all datasets ‚Üí relatively balanced distribution, not heavily skewed.\n",
        "\n",
        "**3. NumOfProducts**\n",
        "\n",
        "* Four levels (1‚Äì4), with **2 products** being the most common (\\~50% of customers).\n",
        "* Levels 3 and 4 have very small proportions ‚Üí can be grouped during analysis or modeling.\n",
        "\n",
        "**4. HasCrCard**\n",
        "\n",
        "* Two values: **1 (has a credit card)** and **0 (does not)**.\n",
        "* Customers with a credit card (**1**) make up the majority (\\~70‚Äì72%) across all datasets.\n",
        "\n",
        "**5. IsActiveMember**\n",
        "\n",
        "* Two values: **1 (active)** and **0 (inactive)**.\n",
        "* Fairly balanced distribution: around 50‚Äì51% active and 49‚Äì50% inactive.\n",
        "\n",
        "**Overall Observations**\n",
        "\n",
        "* The distribution patterns of categorical variables are **almost identical** between the Train, Origin, and Test datasets ‚Üí indicating consistent data with no distribution shift between training and testing sets.\n",
        "* Some features have **uneven distributions** (e.g., Geography and NumOfProducts).\n",
        "* Binary variables like HasCrCard and IsActiveMember have clear distributions and can be easily utilized in analysis or modeling."
      ],
      "metadata": {
        "id": "mn82byuJ4-rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Data Quality Checks</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Data Quality Checks\n",
        "    </h1>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "n9dbM4vI4-rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Value"
      ],
      "metadata": {
        "id": "iYsMro2P4-rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def displayNULL(df, dataset_name=None):\n",
        "    total_rows = len(df)\n",
        "\n",
        "    missing_df = df.isnull().sum().reset_index()\n",
        "    missing_df.columns = [\"Feature\", \"Missing_Count\"]\n",
        "    missing_df = missing_df[missing_df[\"Missing_Count\"] > 0]\n",
        "    missing_df[\"Missing_%\"] = (missing_df[\"Missing_Count\"] / total_rows * 100).round(2)\n",
        "    missing_df = missing_df.sort_values(by=\"Missing_Count\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    total_missing = missing_df[\"Missing_Count\"].sum()\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "    if dataset_name:\n",
        "        print(f\"üîé Missing Value Summary for: {dataset_name}\")\n",
        "    else:\n",
        "        print(\"üîé Missing Value Summary:\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    if total_missing == 0:\n",
        "        print(f\"‚úÖ No missing values detected in {total_rows:,} rows.\")\n",
        "    else:\n",
        "        try:\n",
        "            from tabulate import tabulate\n",
        "            print(tabulate(missing_df, headers=\"keys\", tablefmt=\"pretty\", showindex=False, colalign=(\"left\", \"left\", \"left\")))\n",
        "        except ImportError:\n",
        "            print(missing_df.to_string(index=False))\n",
        "\n",
        "        print(f\"\\n‚ö†Ô∏è  Total missing values: {total_missing:,} out of {total_rows:,} rows.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.103867Z",
          "iopub.execute_input": "2025-08-12T10:18:23.104103Z",
          "iopub.status.idle": "2025-08-12T10:18:23.112257Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.104085Z",
          "shell.execute_reply": "2025-08-12T10:18:23.111346Z"
        },
        "trusted": true,
        "id": "UHrGpSz94-rC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing value train dataset: \")\n",
        "displayNULL(df_train, dataset_name=\"Train Set\")\n",
        "\n",
        "print(\"\\nMissing value Origin dataset: \")\n",
        "displayNULL(df_origin, dataset_name=\"Origin Set\")\n",
        "\n",
        "print(\"\\nMissing value test dataset: \")\n",
        "displayNULL(df_test, dataset_name=\"Test Set\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.113262Z",
          "iopub.execute_input": "2025-08-12T10:18:23.113831Z",
          "iopub.status.idle": "2025-08-12T10:18:23.149063Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.11379Z",
          "shell.execute_reply": "2025-08-12T10:18:23.147985Z"
        },
        "trusted": true,
        "id": "ci-pNAd-4-rD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking duplicate Value"
      ],
      "metadata": {
        "id": "jIuKaIld4-rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_duplicates_report(df, dataset_name):\n",
        "    duplicates_count = df.duplicated().sum()\n",
        "    total_rows = len(df)\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"üîç {dataset_name} Duplicate Analysis\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    if duplicates_count == 0:\n",
        "        print(f\"‚úÖ No duplicates found in {total_rows:,} rows\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  {duplicates_count} duplicates found ({duplicates_count/total_rows:.2%})\")\n",
        "        print(f\"    Total rows affected: {duplicates_count:,}/{total_rows:,}\")\n",
        "\n",
        "datasets = {\n",
        "    \"Training Data\": df_train,\n",
        "    \"Origin Data\":  df_origin,\n",
        "    \"Test Data\": df_test\n",
        "}\n",
        "\n",
        "duplicate_summary = {}\n",
        "for name, data in datasets.items():\n",
        "    check_duplicates_report(data, name)\n",
        "    duplicate_summary[name] = {\n",
        "        \"duplicates\": data.duplicated().sum(),\n",
        "        \"total_rows\": len(data)\n",
        "    }\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.150055Z",
          "iopub.execute_input": "2025-08-12T10:18:23.150282Z",
          "iopub.status.idle": "2025-08-12T10:18:23.259897Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.150265Z",
          "shell.execute_reply": "2025-08-12T10:18:23.258985Z"
        },
        "trusted": true,
        "id": "oLZuhtmI4-rD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate\n",
        "for df in [df_train, df_origin]:\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "for name, data in datasets.items():\n",
        "    check_duplicates_report(data, name)\n",
        "    duplicate_summary[name] = {\n",
        "        \"duplicates\": data.duplicated().sum(),\n",
        "        \"total_rows\": len(data)\n",
        "    }\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.260995Z",
          "iopub.execute_input": "2025-08-12T10:18:23.261323Z",
          "iopub.status.idle": "2025-08-12T10:18:23.423985Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.261301Z",
          "shell.execute_reply": "2025-08-12T10:18:23.422313Z"
        },
        "trusted": true,
        "id": "tjrqa7Ez4-rD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle requires the submission file to have the exact same number of rows as the original `test.csv` file (in this case, **110,023 rows**).\n",
        "\n",
        "If we remove duplicates in the test set ‚Üí the number of rows will decrease ‚Üí Kaggle will return an error upon submission.\n",
        "\n",
        "Therefore:\n",
        "\n",
        "* **Train set** and **Origin set** ‚Üí We need to remove duplicates.\n",
        "* **Test set** ‚Üí Must keep duplicates to ensure the row count matches the original for submission."
      ],
      "metadata": {
        "id": "UcQ-9N8p4-rD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Outlier Value"
      ],
      "metadata": {
        "id": "egRelBzr4-rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
        "cat_features = [\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\", \"NumOfProducts\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.42495Z",
          "iopub.execute_input": "2025-08-12T10:18:23.425184Z",
          "iopub.status.idle": "2025-08-12T10:18:23.431077Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.425167Z",
          "shell.execute_reply": "2025-08-12T10:18:23.429697Z"
        },
        "trusted": true,
        "id": "knyKHXrL4-rE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def checking_outlier(list_feature, df, dataset_name):\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"üîç {dataset_name} Checking outlier\")\n",
        "    print(\"=\" * 40)\n",
        "    outlier_info = []\n",
        "    for feature in list_feature:\n",
        "        Q1 = df[feature].quantile(0.25)\n",
        "        Q3 = df[feature].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)][feature]\n",
        "        if len(outliers) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            outlier_info.append({\n",
        "            \"Feature\": feature,\n",
        "            \"Outlier Count\": len(outliers),\n",
        "            # \"Outlier Detail\": outliers.tolist()\n",
        "            })\n",
        "    return pd.DataFrame(outlier_info)\n",
        "\n",
        "checking_outlier(list_feature=num_features, df=df_train, dataset_name=\"Training data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.432076Z",
          "iopub.execute_input": "2025-08-12T10:18:23.432448Z",
          "iopub.status.idle": "2025-08-12T10:18:23.502681Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.432418Z",
          "shell.execute_reply": "2025-08-12T10:18:23.501693Z"
        },
        "trusted": true,
        "id": "mR6hIMvo4-rE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checking_outlier(list_feature=num_features, df=df_origin, dataset_name=\"Origin data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.503736Z",
          "iopub.execute_input": "2025-08-12T10:18:23.504096Z",
          "iopub.status.idle": "2025-08-12T10:18:23.525515Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.504064Z",
          "shell.execute_reply": "2025-08-12T10:18:23.524762Z"
        },
        "trusted": true,
        "id": "VXkMQR9h4-rE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checking_outlier(list_feature=num_features, df=df_test, dataset_name=\"Test data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.526842Z",
          "iopub.execute_input": "2025-08-12T10:18:23.52713Z",
          "iopub.status.idle": "2025-08-12T10:18:23.568341Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.527111Z",
          "shell.execute_reply": "2025-08-12T10:18:23.567403Z"
        },
        "trusted": true,
        "id": "TMd12yGz4-rF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Quality Insights: Missing Values, Duplicates and Outliers.\n",
        "\n",
        "**Missing Values Analysis**\n",
        "\n",
        "* We conducted a thorough examination for missing values across the **train**, **test**, and **original** datasets.\n",
        "* **No missing values** were detected ‚Äî ensuring clean synthetic data for model training.\n",
        "\n",
        "**Duplicate Records Analysis**\n",
        "\n",
        "* We performed a check for exact duplicate rows that could artificially inflate performance or introduce bias.\n",
        "\n",
        "* **Training Data**:\n",
        "\n",
        "  * **123 duplicate rows** found in 165,034 records.\n",
        "\n",
        "* **Original Data**:\n",
        "\n",
        "  * **2 duplicate rows** found in 9998 records.\n",
        "\n",
        "* **Test Data**:\n",
        "\n",
        "  * **72 duplicates** detected in 110,023 records\n",
        "\n",
        "**Outlier Analysis**\n",
        "\n",
        "* We also examined the datasets for checking outliers.\n",
        "* **The outliers** were found in dataset at features. But we can not remove them since these outliers reflect reality.\n",
        "* Both **train**, **origin** and **test** datasets contain **notable outliers** in `CreditScore`, `Age`.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "* The **synthetic training** and **test datasets** exhibit excellent data quality with **no missing**.\n",
        "* The duplicate record exist across the **train**, **test**, and **original** datasets.\n",
        "* The outlier value exist across the **train**, **test**, and **original** datasets.\n",
        "* Overall, data readiness is high and preprocessing complexity is minimal."
      ],
      "metadata": {
        "id": "vVcAHU2i4-rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Exploratory Data Analysis (EDA)</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Exploratory Data Analysis (EDA)\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "jWJYZgCR4-rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical**\n",
        "\n",
        "‚úÖ Are the Assumptions of T-Test and ANOVA the Same?\n",
        "Yes ‚Äî T-Test and ANOVA share very similar assumptions, as both are parametric tests used to compare group means. However, there are slight differences due to their intended use.\n",
        "\n",
        "‚úÖ Common Assumptions for Both T-Test and ANOVA\n",
        "\n",
        "| **Assumption**                 | **T-Test**                                        | **ANOVA**                             |\n",
        "| ------------------------------ | ------------------------------------------------- | ------------------------------------- |\n",
        "| **1. Dependent variable**      | Continuous                                        | Continuous                            |\n",
        "| **2. Grouping variable**       | Categorical with **2 groups**                     | Categorical with **3 or more groups** |\n",
        "| **3. Normality**               | Data in each group should be normally distributed | Same as T-Test                        |\n",
        "| **4. Homogeneity of variance** | Equal variances across groups (`equal_var=True`)  | Same as T-Test                        |\n",
        "| **5. Independence**            | Observations must be independent                  | Same as T-Test                        |\n",
        "\n",
        "üîÑ Key Differences Between T-Test and ANOVA\n",
        "\n",
        "| **Criterion**           | **T-Test**                   | **ANOVA**                                       |\n",
        "| ----------------------- | ---------------------------- | ----------------------------------------------- |\n",
        "| Number of groups        | Compares **2 groups**        | Compares **3 or more groups**                   |\n",
        "| Post-hoc tests required | Not required                 | Required if significant (e.g., **Tukey‚Äôs HSD**) |\n",
        "| Types of tests          | Independent or Paired T-Test | One-Way or Repeated Measures ANOVA              |\n",
        "\n",
        "üìå Alternatives When Assumptions Are Violated\n",
        "\n",
        "| **Violation**           | **T-Test Alternative**  | **ANOVA Alternative**   |\n",
        "| ----------------------- | ----------------------- | ----------------------- |\n",
        "| Non-normal distribution | **Mann‚ÄìWhitney U Test** | **Kruskal‚ÄìWallis Test** |\n",
        "| Unequal variances       | **Welch‚Äôs T-Test**      | **Welch‚Äôs ANOVA**       |"
      ],
      "metadata": {
        "id": "LYyqhML84-rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def color(n_colors=2):\n",
        "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "    positions = np.linspace(0, 1, n_colors)\n",
        "    colors = [cmap(p) for p in positions]\n",
        "    return colors"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.56947Z",
          "iopub.execute_input": "2025-08-12T10:18:23.569725Z",
          "iopub.status.idle": "2025-08-12T10:18:23.575316Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.569706Z",
          "shell.execute_reply": "2025-08-12T10:18:23.574225Z"
        },
        "trusted": true,
        "id": "Ak1xpLk14-rG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_ChiSquare(cat_feature, target_feature, df, show_expected=False, show_residuals=False):\n",
        "    \"\"\"\n",
        "    Perform a Chi-Square test of independence to evaluate whether two categorical variables\n",
        "    are statistically associated (i.e., dependent) or independent from each other.\n",
        "\n",
        "    This function tests the null hypothesis that the two categorical variables are independent.\n",
        "    It prints the test statistic, degrees of freedom, p-value, and an interpretation based on the p-value.\n",
        "    Optionally, it displays the expected frequency table under independence, and standardized residuals\n",
        "    (including a heatmap) which help to identify specific group-level deviations.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cat_feature : str\n",
        "        Name of the first categorical variable (typically the feature).\n",
        "\n",
        "    target_feature : str\n",
        "        Name of the second categorical variable (typically the target label).\n",
        "\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame containing the data.\n",
        "\n",
        "    show_expected : bool, default=False\n",
        "        If True, prints the expected frequencies under the assumption of independence.\n",
        "\n",
        "    show_residuals : bool, default=False\n",
        "        If True, prints the standardized residuals and shows them as a heatmap\n",
        "        to identify where the strongest associations/deviations occur.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the Chi-Square test result, including statistical significance interpretation.\n",
        "        Optionally prints expected values and standardized residuals.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Hypotheses:\n",
        "        H‚ÇÄ (Null):     The two variables are independent (no association).\n",
        "        H‚ÇÅ (Alt.):      There is a dependency or association between the variables.\n",
        "\n",
        "    - Interpretation:\n",
        "        If p-value < 0.05 ‚Üí Reject H‚ÇÄ ‚Üí Conclude that the variables are significantly associated.\n",
        "        If p-value ‚â• 0.05 ‚Üí Fail to reject H‚ÇÄ ‚Üí No statistically significant association found.\n",
        "\n",
        "    - Standardized residuals:\n",
        "        - Values > +2 or < -2 indicate strong deviation from expected frequency (local dependency).\n",
        "        - Useful for identifying specific group-level contributions to the overall Chi-Square result.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://en.wikipedia.org/wiki/Chi-squared_test\n",
        "    - https://www.scribbr.com/statistics/chi-square-test-of-independence/\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç Chi-Square Test of Independence: '{cat_feature}' vs. '{target_feature}'\")\n",
        "\n",
        "    # Contingency table\n",
        "    crosstab = pd.crosstab(df[cat_feature], df[target_feature])\n",
        "    chi2, p, dof, expected = chi2_contingency(crosstab)\n",
        "\n",
        "    print(f\"Chi-squared statistic: {chi2:.3f}\")\n",
        "    print(f\"Degrees of freedom: {dof}\")\n",
        "    print(f\"p-value: {p:.6f}\")\n",
        "\n",
        "    if p < 0.05:\n",
        "        print(\"‚úÖ Result: p-value < 0.05 ‚Üí Reject H‚ÇÄ\")\n",
        "        print(f\"‚Üí There is a **statistically significant association** between '{cat_feature}' and '{target_feature}'.\")\n",
        "    else:\n",
        "        print(\"‚ùé Result: p-value ‚â• 0.05 ‚Üí Fail to reject H‚ÇÄ\")\n",
        "        print(f\"‚Üí No statistically significant association between '{cat_feature}' and '{target_feature}'.\")\n",
        "\n",
        "    # Optional: show expected frequencies\n",
        "    if show_expected:\n",
        "        print(\"\\nüìä Expected Frequencies:\")\n",
        "        print(pd.DataFrame(expected, index=crosstab.index, columns=crosstab.columns))\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    # Optional: show standardized residuals\n",
        "    if show_residuals:\n",
        "        cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "        residuals = (crosstab - expected) / np.sqrt(expected)\n",
        "        print(\"\\nüìà Standardized Residuals:\")\n",
        "        print(round(residuals, 2))\n",
        "\n",
        "        # Heatmap of residuals\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.heatmap(residuals, annot=True, cmap=cmap, center=0, fmt=\".2f\", linewidths=0.5)\n",
        "        plt.title(f\"Standardized Residuals Heatmap: {cat_feature} vs {target_feature}\")\n",
        "        plt.ylabel(cat_feature)\n",
        "        plt.xlabel(target_feature)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def cal_shapiro(cat_feature, num_feature, df, plot_result=False):\n",
        "    \"\"\"\n",
        "    Perform the Shapiro‚ÄìWilk test to assess normality of a numerical feature\n",
        "    within each group defined by a categorical feature.\n",
        "\n",
        "    This function iterates through all unique, non-null values of a categorical variable,\n",
        "    and applies the Shapiro‚ÄìWilk test to the corresponding subgroup of the numeric variable.\n",
        "    Optionally, it displays a Q-Q plot to visually assess the distribution.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cat_feature : str\n",
        "        The name of the categorical column that defines the groups.\n",
        "\n",
        "    num_feature : str\n",
        "        The name of the numerical column to test for normality.\n",
        "\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame containing the data.\n",
        "\n",
        "    plot_result : bool, optional (default=False)\n",
        "        If True, displays a Q-Q plot for each group to visually assess normality.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the Shapiro‚ÄìWilk test statistic and p-value for each group,\n",
        "        and optionally shows a Q-Q plot.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): The data is normally distributed.\n",
        "    - H‚ÇÅ (alternative): The data is not normally distributed.\n",
        "    - If p > 0.05 ‚Üí fail to reject H‚ÇÄ ‚Üí data appears normal.\n",
        "    - If p ‚â§ 0.05 ‚Üí reject H‚ÇÄ ‚Üí data likely not normal.\n",
        "    - The test is not reliable for n > 5000 (as per scipy recommendation).\n",
        "    - Requires at least 3 non-null values per group.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\n",
        "    - https://www.statskingdom.com/shapiro-wilk-test.html\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üîé Shapiro-Wilk Normality Test for {num_feature} across {cat_feature} groups\")\n",
        "\n",
        "    for group in df[cat_feature].dropna().unique():\n",
        "        data = df[df[cat_feature] == group][num_feature].dropna()\n",
        "        n = len(data)\n",
        "\n",
        "        if n < 3:\n",
        "            print(f\"‚ö†Ô∏è Group {group} has too few values ({n}) to perform Shapiro-Wilk test.\")\n",
        "        elif n > 5000:\n",
        "            print(f\"‚ö†Ô∏è Group {group} has {n} samples. Shapiro-Wilk may not be reliable for n > 5000.\")\n",
        "        else:\n",
        "            stat, p = shapiro(data)\n",
        "            print(f\"Group: {group}\")\n",
        "            print(f\"  Shapiro-Wilk statistic: {stat:.3f}\")\n",
        "            print(f\"  p-value: {p}\")\n",
        "            if p > 0.05:\n",
        "                print(f\" üü¢ Group '{group}' appears to follow a normal distribution.\\n\")\n",
        "            else:\n",
        "                print(f\" ‚ö™ Group '{group}' does not appear to follow a normal distribution.\\n\")\n",
        "\n",
        "            if plot_result:\n",
        "                probplot(data, dist=\"norm\", plot=plt)\n",
        "                plt.title(f\"QQ Plot - {group}\")\n",
        "                plt.show()\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "def cal_levene(dataframe, categorical_feature, num_feature, center=\"mean\"):\n",
        "    \"\"\"\n",
        "    Perform Levene‚Äôs test to assess the equality (homogeneity) of variances\n",
        "    for a numeric feature across two or more groups defined by a categorical feature.\n",
        "\n",
        "    Levene's test is used to verify the assumption of equal variances\n",
        "    (homoscedasticity), which is important for parametric tests such as the\n",
        "    independent t-test and ANOVA.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pd.DataFrame\n",
        "        The input DataFrame containing the features to test.\n",
        "\n",
        "    categorical_feature : str\n",
        "        The name of the categorical column that defines the grouping.\n",
        "\n",
        "    num_feature : str\n",
        "        The name of the numerical column whose variance is being compared across groups.\n",
        "\n",
        "    center : str, optional (default=\"mean\")\n",
        "        Specifies the measure of central tendency to use when calculating deviations:\n",
        "        - \"mean\": classic Levene's test (sensitive to non-normal data)\n",
        "        - \"median\": more robust to non-normal distributions (Brown‚ÄìForsythe test)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the Levene test statistic, p-value, and an interpretation of whether\n",
        "        the variances are equal or significantly different.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (Null Hypothesis): All groups have equal variances.\n",
        "    - H‚ÇÅ (Alternative Hypothesis): At least one group has different variance.\n",
        "    - If p > 0.05 ‚Üí Fail to reject H‚ÇÄ ‚Üí Variances are approximately equal.\n",
        "    - If p ‚â§ 0.05 ‚Üí Reject H‚ÇÄ ‚Üí Variances are significantly different (heteroscedasticity).\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html\n",
        "    - https://www.geeksforgeeks.org/levenes-test-in-python/\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üîç Levene‚Äôs test: {num_feature} ~ {categorical_feature}\")\n",
        "    # Extract unique group labels\n",
        "    groups = dataframe[categorical_feature].unique()\n",
        "    # Create a list of values for each group\n",
        "    data_groups = [dataframe[dataframe[categorical_feature] == g][num_feature] for g in groups]\n",
        "    # Perform Levene‚Äôs test\n",
        "    stat, p = levene(*data_groups, center=center)\n",
        "\n",
        "    print(f\"Levene statistic: {stat:.3f}\")\n",
        "    print(f\"p-value: {p}\")\n",
        "    if p > 0.05:\n",
        "        print(\"üü¢ Variances are approximately equal across groups.\")\n",
        "    else:\n",
        "        print(\"‚ö™ Variances are significantly different across groups.\")\n",
        "\n",
        "def cal_mannwhitneyu(dataframe, categorical_feature, num_feature):\n",
        "    \"\"\"\n",
        "    Perform the Mann‚ÄìWhitney U test (Wilcoxon rank-sum test) to assess whether there\n",
        "    is a statistically significant difference in the distribution of a numerical feature\n",
        "    between two independent groups defined by a binary categorical feature.\n",
        "\n",
        "    The function also compares medians, calculates the effect size (r), provides interpretation,\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pd.DataFrame\n",
        "        The input DataFrame containing the data.\n",
        "\n",
        "    categorical_feature : str\n",
        "        Column name of the categorical feature (must contain exactly 2 unique values).\n",
        "\n",
        "    num_feature : str\n",
        "        Column name of the numerical feature to compare.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the U statistic, p-value, medians, Z-score, effect size r, and interpretation.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (Null Hypothesis): The two groups have the same distribution.\n",
        "    - H‚ÇÅ (Alternative Hypothesis): The distributions are different.\n",
        "    - If p ‚â§ 0.05 ‚Üí reject H‚ÇÄ ‚Üí significant difference.\n",
        "    - Effect size r helps interpret how strong the difference is:\n",
        "        * Small ~0.1, Medium ~0.3, Large ‚â•0.5\n",
        "    \"\"\"\n",
        "\n",
        "    groups = dataframe[categorical_feature].dropna().unique()\n",
        "\n",
        "    if len(groups) != 2:\n",
        "        print(f\"‚ùå Error: Mann-Whitney U test requires exactly 2 groups, but found {len(groups)}.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç Mann‚ÄìWhitney U Test for '{num_feature}' by '{categorical_feature}'\\n\")\n",
        "    print(\"H‚ÇÄ: The distributions of the two groups are equal.\")\n",
        "    print(\"H‚ÇÅ: The distributions are different.\\n\")\n",
        "\n",
        "    group1 = dataframe[dataframe[categorical_feature] == groups[0]][num_feature].dropna()\n",
        "    group2 = dataframe[dataframe[categorical_feature] == groups[1]][num_feature].dropna()\n",
        "\n",
        "    stat, p = mannwhitneyu(group1, group2, alternative=\"two-sided\")\n",
        "\n",
        "    print(f\"U statistic : {stat}\")\n",
        "    print(f\"p-value     : {p}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p <= 0.05:\n",
        "        print(\"\\n‚úÖ Result: Statistically significant difference between the two groups (Reject H‚ÇÄ).\")\n",
        "        median1 = group1.median()\n",
        "        median2 = group2.median()\n",
        "        if median1 > median2:\n",
        "            print(f\" Interpretation: Group '{groups[0]}' has a higher median '{num_feature}' than Group '{groups[1]}'.\")\n",
        "        elif median1 < median2:\n",
        "            print(f\" Interpretation: Group '{groups[1]}' has a higher median '{num_feature}' than Group '{groups[0]}'.\")\n",
        "        else:\n",
        "            print(\" Interpretation: The medians are equal, but distributions may still differ.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö™ Result: No statistically significant difference between the two groups (Fail to reject H‚ÇÄ).\")\n",
        "\n",
        "\n",
        "def t_test_with_cohens_d(data, categorical_feature, num_feature, equal_var = False):\n",
        "    \"\"\"\n",
        "    Perform an Independent Two-Sample T-Test and compute Cohen's d to evaluate\n",
        "    the difference between two independent groups on a numeric variable.\n",
        "\n",
        "    This function tests whether the means of two independent groups are statistically different,\n",
        "    and also calculates the magnitude of the difference (effect size) using Cohen's d.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The input DataFrame containing the categorical and numerical features.\n",
        "\n",
        "    categorical_feature : str\n",
        "        The name of the categorical column used to define the two groups (must have exactly 2 unique values).\n",
        "\n",
        "    num_feature : str\n",
        "        The name of the numerical feature to compare between the two groups.\n",
        "\n",
        "    equal_var : bool, optional (default=False)\n",
        "        Assumes equal population variance if True (Student‚Äôs t-test). If False (default), performs Welch‚Äôs t-test.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the t-statistic, p-value, Cohen‚Äôs d, and interpretation of the effect size.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): The two groups have equal means.\n",
        "    - H‚ÇÅ (alternative): The means are significantly different.\n",
        "    - Cohen's d interpretation:\n",
        "        - 0.2  ‚Üí small effect\n",
        "        - 0.5  ‚Üí medium effect\n",
        "        - 0.8+ ‚Üí large effect\n",
        "    - Welch‚Äôs t-test is recommended when group variances are unequal (default setting).\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://www.scribbr.com/statistics/t-test/\n",
        "    - https://en.wikipedia.org/wiki/Cohen%27s_d\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract unique groups\n",
        "    groups = data[categorical_feature].dropna().unique()\n",
        "\n",
        "    if len(groups) > 2:\n",
        "        print(f\"‚ùå Error: Independent T-Test requires 2 groups.\")\n",
        "        return\n",
        "    else:\n",
        "        print(f\"üîç Independent T-Test: {num_feature} ~ {categorical_feature}\")\n",
        "        # Extract values\n",
        "        x1 = data[data[categorical_feature] == groups[0]][num_feature].dropna()\n",
        "        x2 = data[data[categorical_feature] == groups[1]][num_feature].dropna()\n",
        "\n",
        "        # T-test (independent)\n",
        "        t_stat, p_value = ttest_ind(x1, x2, equal_var=equal_var)  # Welch‚Äôs t-test if variances may differ\n",
        "\n",
        "        # Calculate Cohen‚Äôs d\n",
        "        nx1, nx2 = len(x1), len(x2)\n",
        "        pooled_std = np.sqrt(((nx1 - 1)*np.var(x1, ddof=1) + (nx2 - 1)*np.var(x2, ddof=1)) / (nx1 + nx2 - 2))\n",
        "        cohens_d = (np.mean(x1) - np.mean(x2)) / pooled_std\n",
        "\n",
        "        # Output\n",
        "        print(f\"\\nüîç T-Test between group'{groups[0]}' and group '{groups[1]}':\")\n",
        "        print(f\"t-statistic: {t_stat:.3f}\")\n",
        "        print(f\"p-value: {p_value:.6f}\")\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            print(\"\\n‚úÖ Significant difference found (p < 0.05)\")\n",
        "            print(f\"\\nüìè Cohen's d: {cohens_d:.3f}\")\n",
        "            # Interpretation of Cohen's d\n",
        "            if abs(cohens_d) < 0.2:\n",
        "                size = \"small\"\n",
        "            elif abs(cohens_d) < 0.5:\n",
        "                size = \"medium\"\n",
        "            else:\n",
        "                size = \"large\"\n",
        "            print(f\"üß† Effect size interpretation: {size} effect\")\n",
        "        else:\n",
        "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
        "\n",
        "def perform_anova_with_tukey(df, numeric_feature, categorical_feature, typ=2):\n",
        "    \"\"\"\n",
        "    Perform a One-Way ANOVA test to determine whether there are statistically\n",
        "    significant differences between the means of three or more independent groups.\n",
        "\n",
        "    If the ANOVA test is significant (p < 0.05), Tukey's HSD post-hoc test is performed\n",
        "    to identify which specific pairs of groups differ from each other.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input dataset containing the numeric and categorical features.\n",
        "\n",
        "    numeric_feature : str\n",
        "        The name of the numerical (continuous) response variable.\n",
        "\n",
        "    categorical_feature : str\n",
        "        The name of the categorical (independent) variable used to group the data.\n",
        "\n",
        "    typ : int, optional (default=2)\n",
        "        The type of sum of squares to use in the ANOVA test:\n",
        "        - Type I (1): Sequential.\n",
        "        - Type II (2): Default and commonly used for balanced designs.\n",
        "        - Type III (3): Use when model includes interaction terms or unbalanced data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the ANOVA table, p-value, interpretation, and (if significant) the Tukey HSD test summary.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): All group means are equal.\n",
        "    - H‚ÇÅ (alternative hypothesis): At least one group mean is different.\n",
        "    - If p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí perform Tukey‚Äôs HSD to find which groups differ.\n",
        "    - Assumptions:\n",
        "        1. Independence of observations\n",
        "        2. Normally distributed groups (Shapiro or Anderson test can check this)\n",
        "        3. Homogeneity of variances (Levene's test)\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://www.scribbr.com/statistics/one-way-anova/\n",
        "    - https://en.wikipedia.org/wiki/Analysis_of_variance\n",
        "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tukey_hsd.html\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract unique groups\n",
        "    groups = df[categorical_feature].dropna().unique()\n",
        "\n",
        "    if len(groups) < 3:\n",
        "        print(f\"‚ùå Error: ANOVA requires 3 or more groups.\")\n",
        "        return\n",
        "    else:\n",
        "        print(f\"\\nüîç ANOVA Test: {numeric_feature} ~ {categorical_feature} (Type {typ})\")\n",
        "\n",
        "        # Fit OLS model\n",
        "        model = ols(f\"{numeric_feature} ~ C({categorical_feature})\", data=df).fit()\n",
        "\n",
        "        # Perform ANOVA\n",
        "        anova_table = anova_lm(model, typ=typ)\n",
        "        print(\"\\nüìä ANOVA Table:\")\n",
        "        print(anova_table)\n",
        "\n",
        "        # Extract p-value\n",
        "        p_value = anova_table[\"PR(>F)\"].iloc[0]\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            print(\"\\n‚úÖ Significant difference found (p < 0.05)\")\n",
        "            print(\"‚û°Ô∏è Performing Tukey's HSD post-hoc test:\")\n",
        "\n",
        "            tukey = pairwise_tukeyhsd(df[numeric_feature], df[categorical_feature])\n",
        "            print(tukey.summary())\n",
        "        else:\n",
        "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
        "\n",
        "def perform_kruskal_test(df, categorical_feature, numeric_feature):\n",
        "    \"\"\"\n",
        "    Perform the Kruskal-Wallis H-test to determine whether there are statistically\n",
        "    significant differences in the distribution of a numeric variable across\n",
        "    three or more independent groups.\n",
        "\n",
        "    If the result is significant (p < 0.05), Dunn's post-hoc test with Bonferroni correction\n",
        "    is performed to identify which group pairs differ.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input dataset containing the categorical and numerical variables.\n",
        "\n",
        "    categorical_feature : str\n",
        "        The name of the categorical feature that defines the groups.\n",
        "\n",
        "    numeric_feature : str\n",
        "        The name of the numeric feature to be compared across groups.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the Kruskal-Wallis H-statistic, p-value, interpretation, and\n",
        "        optionally the results of Dunn's post-hoc test.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): The distribution of the numeric variable is the same across all groups.\n",
        "    - H‚ÇÅ (alternative hypothesis): At least one group has a different distribution.\n",
        "    - If p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí use Dunn‚Äôs test to explore specific group differences.\n",
        "    - Kruskal-Wallis is a non-parametric alternative to one-way ANOVA.\n",
        "    - It does not assume normality, but assumes:\n",
        "        1. Independent samples\n",
        "        2. Ordinal or continuous response variable\n",
        "        3. Similar shapes of distributions\n",
        "\n",
        "    Requirements\n",
        "    ------------\n",
        "    - `scipy.stats.kruskal`\n",
        "    - `scikit-posthocs` package for Dunn‚Äôs test (`import scikit_posthocs as sp`)\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://www.geeksforgeeks.org/kruskal-wallis-test/\n",
        "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html\n",
        "    - https://scikit-posthocs.readthedocs.io/en/latest/index.html\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract values\n",
        "    groups = df[categorical_feature].dropna().unique()\n",
        "    if len(groups) < 3:\n",
        "        print(f\"‚ùå Error: Kruskal-Wallis H-test requires 3 or more groups.\")\n",
        "        return\n",
        "    else:\n",
        "        print(f\"\\nüîç Kruskal-Wallis Test: {numeric_feature} ~ {categorical_feature}\")\n",
        "        data_groups = [df[df[categorical_feature] == g][numeric_feature].dropna() for g in groups]\n",
        "\n",
        "        # Perform kruskal\n",
        "        stat, p = kruskal(*data_groups)\n",
        "\n",
        "        print(f\"Kruskal-Wallis H-statistic: {stat:.3f}\")\n",
        "        print(f\"p-value: {p}\")\n",
        "\n",
        "        if p < 0.05:\n",
        "            print(\"üü¢ Significant difference found. Running Dunn's Post-Hoc Test...\")\n",
        "            dunn_result = sp.posthoc_dunn(df, val_col=numeric_feature, group_col=categorical_feature, p_adjust=\"bonferroni\")\n",
        "            print(dunn_result)\n",
        "        else:\n",
        "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
        "\n",
        "def cal_Anderson(df, numerical_col, group_col):\n",
        "    \"\"\"\n",
        "    Perform the Anderson‚ÄìDarling test to assess whether the data within each group\n",
        "    follows a normal distribution.\n",
        "\n",
        "    This function applies the Anderson-Darling normality test for each subgroup\n",
        "    defined by a categorical column, and optionally plots KDE distributions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input dataset.\n",
        "\n",
        "    numerical_col : str\n",
        "        The name of the numeric column to test for normality.\n",
        "\n",
        "    group_col : str\n",
        "        The name of the categorical column defining the groups to be tested separately.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the Anderson‚ÄìDarling test statistic, critical values, and interpretation\n",
        "        for each group. Optionally displays a KDE plot for visual comparison.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): The data follows a normal distribution.\n",
        "    - If test statistic > critical value ‚Üí ‚ùå Reject H‚ÇÄ ‚Üí Data is not normally distributed.\n",
        "    - If test statistic ‚â§ critical value ‚Üí ‚úÖ Fail to reject H‚ÇÄ ‚Üí Data may be normal.\n",
        "    - The test is more sensitive to deviations in the tails of the distribution than other tests like Shapiro-Wilk.\n",
        "\n",
        "    Limitations\n",
        "    ----------\n",
        "    - Not recommended for very small sample sizes (< 8).\n",
        "    - Not reliable for very large sample sizes where even small deviations may be flagged.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html\n",
        "    - https://www.itl.nist.gov/div898/handbook/eda/section3/eda35e.htm\n",
        "    - https://en.wikipedia.org/wiki/Anderson‚ÄìDarling_test\n",
        "    \"\"\"\n",
        "\n",
        "    groups = df[group_col].dropna().unique()\n",
        "\n",
        "    print(f\"üìä Checking normality of '{numerical_col}' across groups of '{group_col}' using Anderson-Darling Test:\\n\")\n",
        "    print(\"‚ÑπÔ∏è  H‚ÇÄ: The data follows a normal distribution.\")\n",
        "    print(\"‚ÑπÔ∏è  If test statistic > critical value ‚Üí ‚ùå Reject H‚ÇÄ ‚Üí Not normally distributed.\\n\")\n",
        "\n",
        "    for group in groups:\n",
        "        data = df[df[group_col] == group][numerical_col].dropna()\n",
        "        result = anderson(data, dist=\"norm\")\n",
        "\n",
        "        print(f\"Group = {group}\")\n",
        "        print(f\"  - Sample size: {len(data)}\")\n",
        "        print(f\"  - Test statistic: {result.statistic:.4f}\")\n",
        "\n",
        "        for sl, cv in zip(result.significance_level, result.critical_values):\n",
        "            verdict = \"‚ùå Reject H‚ÇÄ ‚Üí Not normal\" if result.statistic > cv else \"‚úÖ Fail to reject H‚ÇÄ ‚Üí Possibly normal\"\n",
        "            print(f\"    - Œ± = {sl}% | CV = {cv:.4f} ‚Üí {verdict}\")\n",
        "        print()\n",
        "\n",
        "\n",
        "def cal_normaltest(cat_feature, num_feature, df):\n",
        "    \"\"\"\n",
        "    Perform D‚ÄôAgostino and Pearson‚Äôs normality test on a numerical feature\n",
        "    across groups defined by a categorical feature.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cat_feature : str\n",
        "        The name of the categorical column that defines the groups.\n",
        "\n",
        "    num_feature : str\n",
        "        The name of the numerical column to test for normality.\n",
        "\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame containing the data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints the test statistic and p-value for each group.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - H‚ÇÄ (null hypothesis): The data is normally distributed.\n",
        "    - H‚ÇÅ (alternative): The data is not normally distributed.\n",
        "    - If p > 0.05 ‚Üí fail to reject H‚ÇÄ ‚Üí data appears normal.\n",
        "    - If p ‚â§ 0.05 ‚Üí reject H‚ÇÄ ‚Üí data likely not normal.\n",
        "    - Recommended for n ‚â• 20, especially reliable for n > 50.\n",
        "    - Requires at least 8 non-null values per group (as per scipy recommendation).\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üîé D‚ÄôAgostino and Pearson Normality Test for '{num_feature}' across '{cat_feature}' groups\\n\")\n",
        "\n",
        "    for group in df[cat_feature].dropna().unique():\n",
        "        data = df[df[cat_feature] == group][num_feature].dropna()\n",
        "        n = len(data)\n",
        "\n",
        "        print(f\" Group: {group} (n = {n})\")\n",
        "\n",
        "        if n < 8:\n",
        "            print(f\"‚ö†Ô∏è Too few observations (< 8) to perform the test.\\n\")\n",
        "            continue\n",
        "\n",
        "        stat, p = normaltest(data)\n",
        "\n",
        "        print(f\"  Statistic : {stat:.3f}\")\n",
        "        print(f\"  p-value   : {p:.5f}\")\n",
        "\n",
        "        if p > 0.05:\n",
        "            print(f\"  üü¢ Interpretation: Data appears to follow a normal distribution.\\n\")\n",
        "        else:\n",
        "            print(f\"  üî¥ Interpretation: Data does not appear to follow a normal distribution.\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.581863Z",
          "iopub.execute_input": "2025-08-12T10:18:23.582163Z",
          "iopub.status.idle": "2025-08-12T10:18:23.620994Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.582144Z",
          "shell.execute_reply": "2025-08-12T10:18:23.61954Z"
        },
        "trusted": true,
        "id": "t_uRoaSC4-rG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exited Distribution"
      ],
      "metadata": {
        "id": "fQ6UHARW4-rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set target variable\n",
        "target_variable = \"Exited\"\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "datasets = [(\"Train Data\", df_train), (\"Original Data\", df_origin)]\n",
        "\n",
        "for i, (title, data) in enumerate(datasets):\n",
        "    ax = axes[i, 0]\n",
        "    sns.countplot(x=target_variable, data=data, ax=ax, palette=color(n_colors=2))\n",
        "    ax.set_title(f\"Count Plot of Exited in {title}\", pad=20, weight=\"bold\")\n",
        "    ax.set_ylabel(\"Number of Customer\")\n",
        "    ax.set_xlabel(\"Exited\")\n",
        "    ax.set_xticks([0, 1], [\"Not churned\", \"churned\"])\n",
        "\n",
        "    sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
        "\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, fmt=\"%d\", label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
        "\n",
        "    loan_counts = data[target_variable].value_counts().sort_index()\n",
        "    wedges, texts, autotexts = axes[i, 1].pie(\n",
        "        loan_counts,\n",
        "        labels = [\"Not Churned\", \"Churned\"],\n",
        "        autopct=\"%1.1f%%\",\n",
        "        startangle=90,\n",
        "        colors=color(n_colors=2),\n",
        "        wedgeprops=dict(width=0.4, edgecolor=\"w\"),\n",
        "        radius=1.2,\n",
        "        explode = (0, 0.08)\n",
        "    )\n",
        "\n",
        "    for text in texts + autotexts:\n",
        "        text.set_fontsize(10)\n",
        "        text.set_fontweight(\"bold\")\n",
        "\n",
        "    centre_circle = plt.Circle((0, 0), 0.70, fc=\"white\")\n",
        "    axes[i, 1].add_artist(centre_circle)\n",
        "    axes[i, 1].set_title(f\"Exited in {title}\", pad=20, weight=\"bold\")\n",
        "    axes[i, 1].axis(\"equal\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:23.622042Z",
          "iopub.execute_input": "2025-08-12T10:18:23.622312Z",
          "iopub.status.idle": "2025-08-12T10:18:24.296537Z",
          "shell.execute_reply.started": "2025-08-12T10:18:23.622291Z",
          "shell.execute_reply": "2025-08-12T10:18:24.29558Z"
        },
        "trusted": true,
        "id": "gByxCCa94-rM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Distribution Analysis of Customer Churn**\n",
        "\n",
        "**1. Overview of Class Distribution**\n",
        "\n",
        "The visualizations compare the distribution of the target variable `Exited` (Customer Churn) across **Training Data** and **Original Data** using:\n",
        "\n",
        "* **Count plots** showing absolute customer counts.\n",
        "* **Donut charts** displaying percentage proportions.\n",
        "\n",
        "**A. Training Data**\n",
        "\n",
        "**Count Statistics**\n",
        "\n",
        "* `Not Churned`: **130,002 customers**\n",
        "* `Churned`: **34,909 customers**\n",
        "\n",
        "**Percentage Distribution**\n",
        "\n",
        "* `Not Churned`: **78.8%**\n",
        "* `Churned`: **21.2%**\n",
        "\n",
        "> **Insight**:\n",
        "> The training dataset is **imbalanced**, with non-churned customers forming the majority. Roughly **1 in 5** customers have churned.\n",
        "\n",
        "**B. Original Data**\n",
        "\n",
        "**Count Statistics**\n",
        "\n",
        "* `Not Churned`: **7,959 customers**\n",
        "* `Churned`: **2,037 customers**\n",
        "\n",
        "**Percentage Distribution**\n",
        "\n",
        "* `Not Churned`: **79.6%**\n",
        "* `Churned`: **20.4%**\n",
        "\n",
        "> **Insight**:\n",
        "> The original dataset shows a **similar churn ratio** to the training dataset, with around **1 in 5** customers having churned.\n",
        "\n",
        "**2. Key Observations & Implications**\n",
        "\n",
        "| Aspect                   | Training Data       | Original Data       | Observation                                                 |\n",
        "| ------------------------ | ------------------- | ------------------- | ----------------------------------------------------------- |\n",
        "| Majority Class           | Not Churned (78.8%) | Not Churned (79.6%) | Both datasets are skewed toward the ‚ÄúNot Churned‚Äù class     |\n",
        "| Minority Class           | Churned (21.2%)     | Churned (20.4%)     | Minority class is consistent across datasets                |\n",
        "| Class Imbalance Severity | Moderate            | Moderate            | Class proportions are quite similar                         |\n",
        "| Risk of Bias             | Yes                 | Yes                 | Models may overpredict the majority class without balancing |\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Both datasets display **moderate class imbalance**, with churned customers consistently around 20% of the population."
      ],
      "metadata": {
        "id": "YvhmgGBr4-rM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numerical Feature Distributions"
      ],
      "metadata": {
        "id": "5o2wVYUq4-rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_numerical_features(df_train, df_test, df_origin, num_features):\n",
        "    colors = color(n_colors=3)\n",
        "    n = len(num_features)\n",
        "\n",
        "    fig, ax = plt.subplots(n, 2, figsize=(12, n * 4))\n",
        "    ax = np.array(ax).reshape(n, 2)\n",
        "\n",
        "    for i, feature in enumerate(num_features):\n",
        "        sns.histplot(data=df_train[feature], color=colors[0], bins=20, kde=True, ax=ax[i, 0], label=\"Train data\")\n",
        "        sns.histplot(data=df_origin[feature], color=colors[1], bins=20, kde=True, ax=ax[i, 0], label=\"Origin data\")\n",
        "        sns.histplot(data=df_test[feature], color=colors[2], bins=20, kde=True, ax=ax[i, 0], label=\"Test data\")\n",
        "        ax[i, 0].set_title(f\"Histogram of {feature}\", pad=20, weight=\"bold\")\n",
        "        ax[i, 0].legend()\n",
        "        ax[i, 0].set_ylabel(\"\")\n",
        "        ax[i, 0].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
        "        # ax[i, 0].axvline(df_train[feature].median(), color=\"green\", linestyle=\"--\", label=\"Median Train\")\n",
        "        # ax[i, 0].axvline(df_origin[feature].median(), color=\"red\", linestyle=\"--\", label=\"Median Origin\")\n",
        "        # ax[i, 0].axvline(df_test[feature].median(), color=\"orange\", linestyle=\"--\", label=\"Median Test\")\n",
        "        sns.despine(left=False, bottom=False, ax=ax[i, 0])\n",
        "\n",
        "        df_plot = pd.concat([\n",
        "            pd.DataFrame({\"Dataset\": \"Train data\", feature: df_train[feature]}),\n",
        "            pd.DataFrame({\"Dataset\": \"Origin data\", feature: df_origin[feature]}),\n",
        "            pd.DataFrame({\"Dataset\": \"Test data\", feature: df_test[feature]})\n",
        "        ]).reset_index(drop=True)\n",
        "\n",
        "        sns.boxplot(\n",
        "            data=df_plot,\n",
        "            x=feature,\n",
        "            y=\"Dataset\",\n",
        "            palette=colors,\n",
        "            orient=\"h\",\n",
        "            ax=ax[i, 1]\n",
        "        )\n",
        "        ax[i, 1].set_title(f\"Horizontal Violin plot of {feature}\", pad=20, weight=\"bold\")\n",
        "        ax[i, 1].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
        "        sns.despine(left=False, bottom=False, ax=ax[i, 1])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_numerical_features(df_train = df_train, df_test = df_test, df_origin = df_origin, num_features=num_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:24.297799Z",
          "iopub.execute_input": "2025-08-12T10:18:24.298159Z",
          "iopub.status.idle": "2025-08-12T10:18:32.823551Z",
          "shell.execute_reply.started": "2025-08-12T10:18:24.298126Z",
          "shell.execute_reply": "2025-08-12T10:18:32.822433Z"
        },
        "trusted": true,
        "id": "vkuXqWO-4-rN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def check_skewness(data, dataset_name, numerical_features = num_features, highlight=True, sort=True):\n",
        "    skewness_dict = {}\n",
        "    skew_feature = []\n",
        "    for feature in numerical_features:\n",
        "        skew = data[feature].skew(skipna=True)\n",
        "        skewness_dict[feature] = skew\n",
        "\n",
        "    skew_df = pd.DataFrame.from_dict(skewness_dict, orient=\"index\", columns=[\"Skewness\"])\n",
        "    if sort:\n",
        "        skew_df = skew_df.reindex(skew_df[\"Skewness\"].abs().sort_values(ascending=False).index)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    print(f\"\\nüîç Skewness for {dataset_name}:\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Feature':<30} | {'Skewness':<9} | {'Remark'}\")\n",
        "    print(\"-\"*70)\n",
        "    for feature, row in skew_df.iterrows():\n",
        "        skew = row[\"Skewness\"]\n",
        "        abs_skew = abs(skew)\n",
        "        if abs_skew > 1:\n",
        "            remark = \"Highly skewed\"\n",
        "            color = \"\\033[91m\"\n",
        "        elif abs_skew > 0.5:\n",
        "            remark = \"Moderately skewed\"\n",
        "            color = \"\\033[93m\"\n",
        "        else:\n",
        "            remark = \"Approximately symmetric\"\n",
        "            color = \"\"\n",
        "        endc = \"\\033[0m\" if color else \"\"\n",
        "        if highlight and color:\n",
        "            print(f\"{color}{feature:<30} | {skew:>+9.4f} | {remark}{endc}\")\n",
        "            skew_feature.append(feature)\n",
        "        else:\n",
        "            print(f\"{feature:<30} | {skew:>+9.4f} | {remark}\")\n",
        "    print(\"-\"*70)\n",
        "    return skew_feature, skew_df\n",
        "\n",
        "skew_feature_origin, skew_origin_df = check_skewness(df_origin, \"Original Data\")\n",
        "skew_feature_train, skew_train_df = check_skewness(df_train, \"Train Data\")\n",
        "skew_feature_test, skew_test_df = check_skewness(df_test, \"Test Data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:32.824625Z",
          "iopub.execute_input": "2025-08-12T10:18:32.824953Z",
          "iopub.status.idle": "2025-08-12T10:18:32.867548Z",
          "shell.execute_reply.started": "2025-08-12T10:18:32.824928Z",
          "shell.execute_reply": "2025-08-12T10:18:32.866762Z"
        },
        "trusted": true,
        "id": "XL4QP3Pl4-rN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights on Numerical Feature Distributions\n",
        "\n",
        "**Distribution Consistency Across Datasets**\n",
        "\n",
        "* **Histograms** and **violin plots** of numerical features (`CreditScore`, `Age`, `Tenure`, `Balance`, `EstimatedSalary`) show that the **train**, **test**, and **original** datasets share **very similar distributions**.\n",
        "* This strong alignment suggests that the data preparation or synthetic generation process successfully preserved the statistical characteristics of the original dataset, minimizing the risk of **distributional shift** and supporting better **model generalization**.\n",
        "\n",
        "**Shape and Spread of Distributions**\n",
        "\n",
        "* **Histograms** reveal that most variables follow approximately symmetric distributions, except for `Age`, which shows a noticeable right skew.\n",
        "* **Balance** exhibits a unique pattern with a large number of zero values and a secondary peak at higher balances, hinting at two distinct customer groups: those with no account balance and those with substantial deposits.\n",
        "* **Box plots** confirm consistent location, spread, and density across datasets, indicating no significant deviation between training, test, and original data.\n",
        "\n",
        "**Skewness Analysis**\n",
        "\n",
        "* Across all datasets:\n",
        "\n",
        "  * `Age` shows **moderate to high positive skewness** (`+0.97` to `+1.01`), indicating that most customers are clustered in younger age ranges, with fewer older customers stretching the distribution‚Äôs tail.\n",
        "  * All other features (`Balance`, `EstimatedSalary`, `CreditScore`, `Tenure`) are **approximately symmetric** (|skewness| < 0.5).\n",
        "\n",
        "**Feature-Specific Observations**\n",
        "\n",
        "* **CreditScore:**\n",
        "  * Normally distributed, centered around 650‚Äì660, with minimal variation between datasets.\n",
        "\n",
        "* **Age:**\n",
        "  * Skewed toward younger customers (30‚Äì40 years old) with fewer older individuals.\n",
        "\n",
        "* **Tenure:**\n",
        "  * Evenly spread from 0 to 10 years, indicating a balanced distribution of customer loyalty periods.\n",
        "\n",
        "* **Balance:**\n",
        "  * Two prominent groups: customers with no balance and customers with large balances (>100k).\n",
        "\n",
        "* **EstimatedSalary:**\n",
        "  * Uniformly distributed across the full salary range, indicating no major bias in income levels.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "* The high degree of similarity between the train, test, and original datasets indicates **robust data representativeness**.\n",
        "* The only feature requiring potential transformation is `Age`, due to its skewness, which could be addressed via **log**, **Box-Cox**, or **Yeo-Johnson** transformations depending on modeling needs."
      ],
      "metadata": {
        "id": "rCj9Fz5n4-rN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Analysis of Numerical Features"
      ],
      "metadata": {
        "id": "Jj5rGF4D4-rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation(df_train, df_origin, df_test, origin_name=\"Origin Data\", train_name=\"Train Data\", test_name=\"Test Data\"):\n",
        "    corr_train = df_train.corr(numeric_only=True)\n",
        "    corr_origin = df_origin.corr(numeric_only=True)\n",
        "    corr_test = df_test.corr(numeric_only=True)\n",
        "\n",
        "    mask_train = np.triu(np.ones_like(corr_train, dtype=bool))\n",
        "    adjusted_mask_train = mask_train[1:, :-1]\n",
        "    adjusted_cereal_corr_train = corr_train.iloc[1:, :-1]\n",
        "\n",
        "    mask_origin = np.triu(np.ones_like(corr_origin, dtype=bool))\n",
        "    adjusted_mask_origin = mask_origin[1:, :-1]\n",
        "    adjusted_cereal_corr_origin = corr_origin.iloc[1:, :-1]\n",
        "\n",
        "    mask_test = np.triu(np.ones_like(corr_test, dtype=bool))\n",
        "    adjusted_mask_test = mask_test[1:, :-1]\n",
        "    adjusted_cereal_corr_test = corr_test.iloc[1:, :-1]\n",
        "\n",
        "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(24, 10))\n",
        "\n",
        "    sns.heatmap(data=adjusted_cereal_corr_train, mask=adjusted_mask_train,\n",
        "                annot=True, fmt=\".2f\", cmap=cmap,\n",
        "                vmin=-1, vmax=1, linecolor=\"white\", linewidths=0.5, ax=ax[0])\n",
        "    ax[0].set_title(f\"Correlation Heatmap of {train_name}\", fontsize=16, weight=\"bold\")\n",
        "\n",
        "    sns.heatmap(data=adjusted_cereal_corr_test, mask=adjusted_mask_test,\n",
        "                annot=True, fmt=\".2f\", cmap=cmap,\n",
        "                vmin=-1, vmax=1, linecolor=\"white\", linewidths=0.5, ax=ax[1])\n",
        "    ax[1].set_title(f\"Correlation Heatmap of {test_name}\", fontsize=16, weight=\"bold\")\n",
        "\n",
        "    sns.heatmap(data=adjusted_cereal_corr_origin, mask=adjusted_mask_origin,\n",
        "                annot=True, fmt=\".2f\", cmap=cmap,\n",
        "                vmin=-1, vmax=1, linecolor=\"white\", linewidths=0.5, ax=ax[2])\n",
        "    ax[2].set_title(f\"Correlation Heatmap of {origin_name}\", fontsize=16, weight=\"bold\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_correlation(df_train=df_train.drop(columns=\"Exited\", axis=1),\n",
        "                 df_origin=df_origin.drop(columns=\"Exited\", axis=1),\n",
        "                 df_test=df_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:32.86884Z",
          "iopub.execute_input": "2025-08-12T10:18:32.869203Z",
          "iopub.status.idle": "2025-08-12T10:18:33.759104Z",
          "shell.execute_reply.started": "2025-08-12T10:18:32.869173Z",
          "shell.execute_reply": "2025-08-12T10:18:33.758145Z"
        },
        "trusted": true,
        "id": "wckTR4qP4-rN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Correlation Analysis of Numerical Features\n",
        "\n",
        "**Overall Weak Correlations:** Most correlation coefficients are extremely close to zero, indicating very weak or no linear relationship between the numerical features.\n",
        "\n",
        "**Implications for Modeling**\n",
        "\n",
        "- The near-zero correlations imply that each numerical feature provides **unique, non-redundant information**.\n",
        "- Since multicollinearity is not an issue, these features can be safely used together in models like linear regression or tree-based methods."
      ],
      "metadata": {
        "id": "7lxfvnbb4-rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical Feature Distributions"
      ],
      "metadata": {
        "id": "Yk26hHPE4-rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_categorical_distribution(cat_features, df_train, df_test, df_origin, order=None):\n",
        "    for feature in cat_features:\n",
        "        fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(25, 10))\n",
        "\n",
        "        # Determine order dynamically if not provided\n",
        "        if order is None:\n",
        "            unique_vals = sorted(df_train[feature].dropna().unique())\n",
        "        else:\n",
        "            unique_vals = order\n",
        "\n",
        "        # COUNT PLOT ‚Äì TRAIN\n",
        "        sns.countplot(data=df_train, x=feature, ax=ax[0, 0],\n",
        "                      palette=color(n_colors=len(unique_vals)), order=unique_vals)\n",
        "        ax[0, 0].set_title(f\"[Train] Count plot of {feature}\", fontsize=13, pad=12, weight=\"bold\")\n",
        "        ax[0, 0].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        sns.despine(ax=ax[0, 0], left=False, bottom=False)\n",
        "        for container in ax[0, 0].containers:\n",
        "            ax[0, 0].bar_label(container, fmt='%d', label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
        "\n",
        "        # COUNT PLOT ‚Äì ORIGIN\n",
        "        sns.countplot(data=df_origin, x=feature, ax=ax[0, 1],\n",
        "                      palette=color(n_colors=len(unique_vals)), order=unique_vals)\n",
        "        ax[0, 1].set_title(f\"[Origin] Count plot of {feature}\", fontsize=13, pad=12, weight=\"bold\")\n",
        "        ax[0, 1].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        sns.despine(ax=ax[0, 1], left=False, bottom=False)\n",
        "        for container in ax[0, 1].containers:\n",
        "            ax[0, 1].bar_label(container, fmt='%d', label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
        "\n",
        "        # COUNT PLOT ‚Äì TEST\n",
        "        sns.countplot(data=df_test, x=feature, ax=ax[0, 2],\n",
        "                      palette=color(n_colors=len(unique_vals)), order=unique_vals)\n",
        "        ax[0, 2].set_title(f\"[Test] Count plot of {feature}\", fontsize=13, pad=12, weight=\"bold\")\n",
        "        ax[0, 2].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        sns.despine(ax=ax[0, 2], left=False, bottom=False)\n",
        "        for container in ax[0, 2].containers:\n",
        "            ax[0, 2].bar_label(container, fmt='%d', label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
        "\n",
        "        # PERCENTAGE BARPLOT ‚Äì TRAIN\n",
        "        train_percent = df_train[feature].value_counts(normalize=True) * 100\n",
        "        train_percent = train_percent.reindex(unique_vals).fillna(0)\n",
        "        sns.barplot(x=train_percent.index, y=train_percent.values, ax=ax[1, 0],\n",
        "                    palette=color(n_colors=len(unique_vals)))\n",
        "        ax[1, 0].set_title(f\"[Train] Percentage Distribution of {feature}\", pad=10, weight=\"bold\")\n",
        "        sns.despine(ax=ax[1, 0], left=False, bottom=False)\n",
        "        ax[1, 0].set_ylabel(\"Percentage (%)\")\n",
        "        ax[1, 0].set_xlabel(feature)\n",
        "        ax[1, 0].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        for i, v in enumerate(train_percent.values):\n",
        "            ax[1, 0].text(i, v + 0.5, f\"{v:.1f}%\", ha='center', fontsize=10, weight=\"bold\")\n",
        "\n",
        "        # PERCENTAGE BARPLOT ‚Äì ORIGIN\n",
        "        origin_percent = df_origin[feature].value_counts(normalize=True) * 100\n",
        "        origin_percent = origin_percent.reindex(unique_vals).fillna(0)\n",
        "        sns.barplot(x=origin_percent.index, y=origin_percent.values, ax=ax[1, 1],\n",
        "                    palette=color(n_colors=len(unique_vals)))\n",
        "        ax[1, 1].set_title(f\"[Origin] Percentage Distribution of {feature}\", pad=10, weight=\"bold\")\n",
        "        sns.despine(ax=ax[1, 1], left=False, bottom=False)\n",
        "        ax[1, 1].set_ylabel(\"Percentage (%)\")\n",
        "        ax[1, 1].set_xlabel(feature)\n",
        "        ax[1, 1].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        for i, v in enumerate(origin_percent.values):\n",
        "            ax[1, 1].text(i, v + 0.5, f\"{v:.1f}%\", ha='center', fontsize=10, weight=\"bold\")\n",
        "\n",
        "        # PERCENTAGE BARPLOT ‚Äì TEST\n",
        "        test_percent = df_test[feature].value_counts(normalize=True) * 100\n",
        "        test_percent = test_percent.reindex(unique_vals).fillna(0)\n",
        "        sns.barplot(x=test_percent.index, y=test_percent.values, ax=ax[1, 2],\n",
        "                    palette=color(n_colors=len(unique_vals)))\n",
        "        ax[1, 2].set_title(f\"[Test] Percentage Distribution of {feature}\", pad=10, weight=\"bold\")\n",
        "        sns.despine(ax=ax[1, 2], left=False, bottom=False)\n",
        "        ax[1, 2].set_ylabel(\"Percentage (%)\")\n",
        "        ax[1, 2].set_xlabel(feature)\n",
        "        ax[1, 2].grid(axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
        "        for i, v in enumerate(test_percent.values):\n",
        "            ax[1, 2].text(i, v + 0.5, f\"{v:.1f}%\", ha='center', fontsize=10, weight=\"bold\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "plot_categorical_distribution(cat_features=cat_features, df_train = df_train, df_test = df_test, df_origin=df_origin)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:33.760472Z",
          "iopub.execute_input": "2025-08-12T10:18:33.760883Z",
          "iopub.status.idle": "2025-08-12T10:18:38.331127Z",
          "shell.execute_reply.started": "2025-08-12T10:18:33.760853Z",
          "shell.execute_reply": "2025-08-12T10:18:38.330305Z"
        },
        "trusted": true,
        "id": "7JOJYgLe4-rO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def top_ratio(df_test = df_test, df_train = df_train, df_origin=df_origin, cat_features = cat_features):\n",
        "    dataset_names = [\"Train\", \"Test\", \"Origin\"]\n",
        "    datasets = [df_train, df_origin, df_test]\n",
        "    for i, (data, name) in enumerate(zip(datasets, dataset_names)):\n",
        "        print(f\"{name} Data\")\n",
        "        flagged = False\n",
        "        for feature in cat_features:\n",
        "            freq = data[feature].value_counts(normalize=True)\n",
        "            top_ratio = freq.iloc[0]\n",
        "            if top_ratio > 0.99:\n",
        "                flagged = True\n",
        "                print(f\"‚ö†Ô∏è  {feature}: {top_ratio:.1%} l√† '{freq.index[0]}'\")\n",
        "        if not flagged:\n",
        "            print(\"‚úÖ No feature has a category that makes up more than 99% of its values.\")\n",
        "        print(\"*\" * 50)\n",
        "top_ratio()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:38.332157Z",
          "iopub.execute_input": "2025-08-12T10:18:38.332489Z",
          "iopub.status.idle": "2025-08-12T10:18:38.352301Z",
          "shell.execute_reply.started": "2025-08-12T10:18:38.332462Z",
          "shell.execute_reply": "2025-08-12T10:18:38.351338Z"
        },
        "trusted": true,
        "id": "25QlUSOK4-rO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights on Categorical Feature Distributions\n",
        "\n",
        "**Geography Distribution**\n",
        "The `Geography` feature consists of three categories: **France**, **Germany**, and **Spain**.\n",
        "\n",
        "* Across datasets, **France** consistently dominates with \\~57% share in Train/Test, compared to \\~50% in the Original dataset.\n",
        "* **Germany** and **Spain** have similar but lower proportions, each around 21‚Äì25%.\n",
        "\n",
        "**Interpretation:**\n",
        "This shows a noticeable **overrepresentation of France** in the synthetic Train/Test sets compared to the Original dataset, which could slightly bias models toward patterns prevalent in the French customer segment.\n",
        "\n",
        "> **Implication:**\n",
        "> It may be worth considering stratified sampling or weighting to balance geography representation if fairness across regions is important.\n",
        "\n",
        "**Gender Distribution**\n",
        "The `Gender` variable is binary (**Female**, **Male**).\n",
        "\n",
        "* In all datasets, **Male** customers slightly outnumber Females (\\~56% vs \\~44%).\n",
        "* The distribution is stable between Train, Test, and Original datasets, indicating consistent gender representation.\n",
        "\n",
        "**Interpretation:**\n",
        "The gender distribution is slightly imbalanced toward Males but not excessively skewed, making it less critical to adjust during preprocessing.\n",
        "\n",
        "**HasCrCard Distribution**\n",
        "The `HasCrCard` feature is binary (0 = No, 1 = Yes).\n",
        "\n",
        "* Majority of customers (\\~75%) have a credit card in Train and Test sets, slightly higher than \\~70% in the Original dataset.\n",
        "* The difference suggests synthetic data has a **slightly higher proportion of credit card holders**.\n",
        "\n",
        "**Interpretation:**\n",
        "Since credit card ownership can be a key predictor in churn or credit risk analysis, this proportion shift may slightly influence model behavior toward patterns of cardholders.\n",
        "\n",
        "**IsActiveMember Distribution**\n",
        "The `IsActiveMember` variable is binary (0 = Inactive, 1 = Active).\n",
        "\n",
        "* Distribution is **balanced** across datasets (\\~50% Active, \\~50% Inactive).\n",
        "* Minimal differences between synthetic and original data.\n",
        "\n",
        "**Interpretation:**\n",
        "Balanced representation means no immediate need for adjustment; model training should treat both active and inactive customers fairly.\n",
        "\n",
        "**NumOfProducts Distribution**\n",
        "The `NumOfProducts` feature has four categories (1‚Äì4).\n",
        "\n",
        "* Most customers have **1 or 2 products** (\\~47‚Äì51% each in Train/Test), with only a small proportion having 3 or 4 products (<2%).\n",
        "* The Original dataset has a similar pattern, though slightly more customers with 3 or 4 products.\n",
        "\n",
        "**Interpretation:**\n",
        "The **long-tail distribution** here means that higher product counts (3‚Äì4) are rare, potentially limiting model learning for those customer profiles.\n",
        "\n",
        "> **Implication:**\n",
        "> It may be beneficial to combine rare categories into a single ‚Äú3+ products‚Äù group or apply target encoding with caution to avoid overfitting.\n",
        "\n",
        "**Summary of Categorical Feature Analysis**\n",
        "\n",
        "**Stable features across datasets:**\n",
        "\n",
        "* `Gender` and `IsActiveMember` show consistent distributions.\n",
        "\n",
        "**Slight shifts in synthetic data:**\n",
        "\n",
        "* `Geography` has more **France** representation.\n",
        "* `HasCrCard` has more cardholders than in the original dataset.\n",
        "\n",
        "**Highly imbalanced features:**\n",
        "\n",
        "* `NumOfProducts` is dominated by 1‚Äì2 products, with very few cases in higher categories.\n",
        "\n",
        "**Modeling implications:**\n",
        "\n",
        "* Monitor potential bias from geography and credit card ownership differences.\n",
        "* Consider category grouping for rare product counts to improve model stability."
      ],
      "metadata": {
        "id": "tqiLZrg74-rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bivariate Analysis"
      ],
      "metadata": {
        "id": "kAVDxSVN4-rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, df_origin], axis=0, ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:38.35314Z",
          "iopub.execute_input": "2025-08-12T10:18:38.353377Z",
          "iopub.status.idle": "2025-08-12T10:18:38.365813Z",
          "shell.execute_reply.started": "2025-08-12T10:18:38.353346Z",
          "shell.execute_reply": "2025-08-12T10:18:38.364775Z"
        },
        "trusted": true,
        "id": "czkzMYrE4-rO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "target_feature = \"Exited\"\n",
        "\n",
        "def perform_statical_testing(feature, df_train = df_train, total_categories = 2, target_feature = target_feature):\n",
        "    cal_normaltest(cat_feature=target_feature, num_feature=feature, df=df_train)\n",
        "    if total_categories == 2:\n",
        "        cal_mannwhitneyu(dataframe=df_train, categorical_feature=target_feature, num_feature=feature)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def plot_numerical_distribution_by_Exited(feature, df_train = df_train, target_feature = target_feature, order = None):\n",
        "    \"\"\"\n",
        "    Performs statical testing for each groups (distribution by target_feature) by ANOVA, T-test, Mann-Whitney U test,... <br>\n",
        "    Draw violinplot and histogram to display the distribution for each groups of feature.\n",
        "    Parameters:\n",
        "        feature (str): The name of the column representing the numerical variable.\n",
        "        df_train (pd.DataFrame): The input dataset.\n",
        "        target_feature (str): The name of the column representing the target feature.\n",
        "        order (list): Order items in plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Summary information\n",
        "    df_summary_feature = df_train.groupby(by = target_feature, as_index= False)\\\n",
        "    .agg (\n",
        "        Count = (feature, \"count\"),\n",
        "        Mean = (feature, \"mean\"),\n",
        "        Median = (feature, \"median\"),\n",
        "        Std = (feature, \"std\")\n",
        "    )\n",
        "    df_summary_feature = df_summary_feature.sort_values(by=\"Mean\", ascending=False)\n",
        "\n",
        "    summary_data = [\n",
        "        (\"Overall Mean\", f\"{df_train[feature].mean():.2f}\"),\n",
        "        (\"Overall Median\", f\"{df_train[feature].median()}\"),\n",
        "        (\"Overall Std\", f\"{df_train[feature].std():.2f}\")\n",
        "    ]\n",
        "    summary_html = \"<ul>\" + \"\".join([f\"<li><b>{k}:</b> {v}</li>\" for k, v in summary_data]) + \"</ul>\"\n",
        "    display(HTML(summary_html))\n",
        "    display(df_summary_feature.style.background_gradient(cmap=cm).set_table_attributes('style=\"width:75%; margin:auto;\"'))\n",
        "\n",
        "    perform_statical_testing(feature=feature, target_feature=target_feature)\n",
        "\n",
        "    # Plot distribution\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "    colors = [cmap(0.0), cmap(1.0)]\n",
        "    sns.violinplot(x=target_feature, y=feature, data=df_train, hue=target_feature, palette=colors, ax=ax)\n",
        "    ax.set_title(f\"Violin plot of {feature} distribution by {target_feature}\", pad=15, weight = \"bold\")\n",
        "    ax.set_xlabel(target_feature, labelpad=10)\n",
        "    ax.set_ylabel(feature, labelpad=10)\n",
        "    plt.grid(axis=\"y\", color=\"gray\", linestyle=\":\", alpha=0.7)\n",
        "    sns.despine(left=False, bottom=False, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for feature in num_features:\n",
        "    display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:green;'><b>Distribution of {feature} by {target_feature}</b></h2>\"))\n",
        "    plot_numerical_distribution_by_Exited(feature=feature, df_train=df_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:38.366997Z",
          "iopub.execute_input": "2025-08-12T10:18:38.367396Z",
          "iopub.status.idle": "2025-08-12T10:18:41.982529Z",
          "shell.execute_reply.started": "2025-08-12T10:18:38.367344Z",
          "shell.execute_reply": "2025-08-12T10:18:41.981294Z"
        },
        "trusted": true,
        "id": "zbak4HIE4-rP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insight Numerical Features by Exited\n",
        "\n",
        "`CreditScore` <br>\n",
        "* There is a statistically significant difference in credit scores between customers who churned and those who did not (p-value ‚âà 0).\n",
        "* The non-churn group has a higher median credit score (662 vs. 651). <br>\n",
        "\n",
        "-> The feature *CreditScore* appears to have some influence on churn behavior; however, the impact is relatively minor due to the small difference observed.\n",
        "\n",
        "`Age` <br>\n",
        "- There is a statistically significant difference in age between churned and retained customers.\n",
        "- The median age of churned customers is higher (44 vs. 36), suggesting older individuals are more likely to leave. <br>\n",
        "\n",
        "-> This suggests that age is a significant predictor of customer churn, with older customers being more likely to exit.\n",
        "\n",
        "`Tenure` <br>\n",
        "- Although customers in both the exited and retained groups have the same median tenure of 5 years, the distribution of `Tenure` between the two groups differs significantly in a statistical sense.\n",
        "\n",
        "-> This indicates that tenure has some influence on churn likelihood, but it is not a strong standalone determinant.\n",
        "\n",
        "`Balance` <br>\n",
        "- The test results show a statistically significant difference in account balance between customers who stayed and those who exited.\n",
        "- Customers who exited have a higher median balance (100,253 vs. 0)\n",
        "\n",
        "-> This suggests that Balance is a significant predictor of customer churn, with higher balance being more likely to exit.\n",
        "\n",
        "`EstimatedSalary`<br>\n",
        "* There is a statistically significant difference in credit scores between customers who churned and those who did not (p-value ‚âà 0).\n",
        "* The churn group has a higher median estimated salary  (120378 vs. 116267)."
      ],
      "metadata": {
        "id": "a_cH8ZRN4-rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining function for plotting\n",
        "def bivariate_percent_plot(cat, df, figsize=(15, 6), order = None, rot = 0):\n",
        "\n",
        "    display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:green;'><b>Distribution of {cat} by Exited</b></h2>\"))\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=figsize)\n",
        "    # Plot 1\n",
        "    # Calculate the total number of each \"cat\" by Exited\n",
        "    grouped = df.groupby([cat, \"Exited\"]).size().unstack(fill_value=0)\n",
        "    # Calculate the percentages\n",
        "    percentages = grouped.div(grouped.sum(axis=1), axis=0) * 100\n",
        "    if order is not None:\n",
        "        percentages = percentages.loc[order]\n",
        "\n",
        "    # That method uses HUSL colors, so you need hue, saturation, and lightness.\n",
        "    # I used hsluv.org to select the colors of this chart.\n",
        "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "    # Draw stacked bar plot\n",
        "    ax[0] = percentages.plot(kind=\"bar\", stacked=True, cmap=cmap, ax = ax[0], use_index=True)\n",
        "    for container in ax[0].containers:\n",
        "        ax[0].bar_label(container, fmt='%1.2f%%', label_type=\"center\", weight=\"bold\", fontsize=9)\n",
        "\n",
        "    ax[0].set_title(f\"Percentage of Exited by {cat}\", fontsize=14, weight=\"bold\")\n",
        "    ax[0].set_xlabel(f\"{cat}\", fontsize=12)\n",
        "    ax[0].set_ylabel(\"% Exited Rate\", fontsize=12)\n",
        "    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=rot)\n",
        "    ax[0].legend_.remove()\n",
        "    sns.despine(left=False, bottom=False, ax=ax[0])\n",
        "\n",
        "    # Plot 2\n",
        "    sns.countplot(data=df, hue = \"Exited\", x = cat,\n",
        "                palette=color(n_colors=2), ax=ax[1], order=percentages.index, hue_order = [0, 1])\n",
        "    # Show value for each bar.\n",
        "    for container in ax[1].containers:\n",
        "        ax[1].bar_label(container, fmt='%d', label_type=\"edge\", fontsize=9, weight=\"bold\")\n",
        "\n",
        "    ax[1].set_title(f\"Exited by {cat}\", fontsize=14, weight=\"bold\")\n",
        "    ax[1].set_xlabel(f\"{cat}\", fontsize=12)\n",
        "    ax[1].set_ylabel(\"Number of Customer\", fontsize=12)\n",
        "    ax[1].legend(title=\"Exited\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=rot)\n",
        "    sns.despine(left=False, bottom=False, ax=ax[1])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    cal_ChiSquare(cat_feature=cat, target_feature=\"Exited\", df=df, show_residuals=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:41.983982Z",
          "iopub.execute_input": "2025-08-12T10:18:41.984386Z",
          "iopub.status.idle": "2025-08-12T10:18:42.002696Z",
          "shell.execute_reply.started": "2025-08-12T10:18:41.984334Z",
          "shell.execute_reply": "2025-08-12T10:18:42.001754Z"
        },
        "trusted": true,
        "id": "y_QnXwb84-rP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in cat_features:\n",
        "    bivariate_percent_plot(cat=feature, df= df_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:42.003992Z",
          "iopub.execute_input": "2025-08-12T10:18:42.004295Z",
          "iopub.status.idle": "2025-08-12T10:18:45.384051Z",
          "shell.execute_reply.started": "2025-08-12T10:18:42.004273Z",
          "shell.execute_reply": "2025-08-12T10:18:45.382967Z"
        },
        "trusted": true,
        "id": "Ota2qODl4-rP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insight for Categorical Features by Attrition\n",
        "\n",
        "`Geography` <br>\n",
        "- The Chi-Square test reveals a **strong and statistically significant relationship** between customers‚Äô geographical location and their likelihood of leaving the bank.  \n",
        "- Customers from **Germany show a noticeably higher tendency to leave**, as indicated by a large positive standardized residual (68.73).  \n",
        "- In contrast, customers from **France and Spain tend to stay more than expected**, especially in France, which shows a large negative residual (-31.53 and -16.84).  \n",
        "- Therefore, **‚ÄúGeography‚Äù is a highly influential categorical variable** in churn analysis and should be carefully considered in customer retention strategies.\n",
        "\n",
        "`Gender` <br>\n",
        "* **Gender is a significant factor influencing customer churn behavior**.\n",
        "* **Female customers exhibit a higher churn rate** compared to male customers.\n",
        "\n",
        "This is a clear signal for the business to take action ‚Äî companies should consider **designing customer retention strategies tailored by gender**, especially focusing on enhancing the satisfaction and engagement of female customers.\n",
        "\n",
        "`HasCrCard`\n",
        "\n",
        "Although the churn rate between customers **with a credit card** and **without a credit card** shows only a small difference (22.62% vs. 20.63%), the **Chi-square test** indicates that this difference is **statistically significant** (p-value ‚âà 0).\n",
        "\n",
        "**This means:**\n",
        "* There is a **statistically significant association** between credit card ownership and customer churn.\n",
        "* **Standardized residuals** show that customers **without a credit card** churn more than expected (6.80), while those **with a credit card** churn less than expected (-3.91).\n",
        "\n",
        "`IsActiveMember` <br>\n",
        "- The chart indicates a **strong association** between customer activity status and their likelihood of leaving the bank.\n",
        "- **Inactive customers tend to leave more frequently**, while active ones are more likely to stay.\n",
        "- This suggests that **\"IsActiveMember\" is a key factor influencing churn** and should be considered in customer retention strategies.\n",
        "\n",
        "`NumOfProducts` <br>\n",
        "- There is a **strong and statistically significant relationship** between the number of products a customer uses and their likelihood of leaving the bank.  \n",
        "- Certain product groups, such as customers using **1, 3, or 4 products**, exhibit **higher-than-expected churn**, based on standardized residuals.  \n",
        "- The **‚ÄúNumOfProducts‚Äù variable is a critical factor** that should be considered in churn prediction models and customer retention strategies."
      ],
      "metadata": {
        "id": "ktU-1hhP4-rP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature             | Type        | Statistical Test Used | Relationship with Exited | Summary                                                                                             |\n",
        "| ------------------- | ----------- | --------------------- | ------------------------ | --------------------------------------------------------------------------------------------------- |\n",
        "| **Geography**       | Categorical | Chi-Square Test       | Significant            | Customers from **Germany** are more likely to churn, **France** and **Spain** less likely to churn. |\n",
        "| **Gender**          | Categorical | Chi-Square Test       | Significant            | **Female** customers have a higher churn rate than males.                                           |\n",
        "| **HasCrCard**       | Categorical | Chi-Square Test       | Significant            | Customers **without a credit card** churn more than expected, those **with** churn less.            |\n",
        "| **IsActiveMember**  | Categorical | Chi-Square Test       | Significant            | **Inactive** customers are more likely to churn.                                                    |\n",
        "| **NumOfProducts**   | Categorical | Chi-Square Test       | Significant            | Customers with **1, 3, or 4 products** have higher-than-expected churn.                             |\n",
        "| **CreditScore**     | Numerical   | Mann‚ÄìWhitney U Test   | Significant            | Non-churned customers have slightly **higher median credit scores** (653 vs. 646).                  |\n",
        "| **Age**             | Numerical   | Mann‚ÄìWhitney U Test   | Significant            | Churned customers tend to be **older** (median 45 vs. 36).                                          |\n",
        "| **Balance**         | Numerical   | Mann‚ÄìWhitney U Test   | Significant            | Churned customers have a **notably higher median balance** (109,344 vs. 92,063).                    |\n",
        "| **Tenure**          | Numerical   | Mann‚ÄìWhitney U Test   | Significant        | The distribution of Tenure between the two groups **differs significantly in a statistical** sense.                         |\n",
        "| **EstimatedSalary** | Numerical   | Mann‚ÄìWhitney U Test   | Significant        | The churn group has a **higher median estimated salary**.                                  |\n"
      ],
      "metadata": {
        "id": "KK1bLi_B4-rP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate Analysis\n",
        "\n",
        "(Let's address some business questions)"
      ],
      "metadata": {
        "id": "XoipWsWl4-rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_customer_churnma = df_train.copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:45.385208Z",
          "iopub.execute_input": "2025-08-12T10:18:45.386121Z",
          "iopub.status.idle": "2025-08-12T10:18:45.392824Z",
          "shell.execute_reply.started": "2025-08-12T10:18:45.386089Z",
          "shell.execute_reply": "2025-08-12T10:18:45.391657Z"
        },
        "trusted": true,
        "id": "RGVOzVMm4-rQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Why is the churn rate higher among customers in Germany?"
      ],
      "metadata": {
        "id": "rfA6MHxp4-rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def geography_distribution(df=df_train):\n",
        "    import geopandas as gpd\n",
        "    # 1. Calculate churn rate by Geography: mean() = % of customers who exited\n",
        "    churn_rate_by_geo = df.groupby(\"Geography\")[\"Exited\"].mean()\n",
        "\n",
        "    # 2. Load geojson file (country names must match the \"admin\" column)\n",
        "    world = gpd.read_file(\"https://raw.githubusercontent.com/daominhthuan42/PYTHON_DATA_ANALYST/refs/heads/main/14_BANK_CHURN_CUSTOMER/custom.geo.json\")\n",
        "\n",
        "    # 3. Map churn rate to each country\n",
        "    world[\"churn_rate\"] = world[\"admin\"].map(churn_rate_by_geo)\n",
        "\n",
        "    # 4. Plotting\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Draw base map (entire Europe in grey)\n",
        "    world.plot(ax=ax, color=\"#D3D3D3\", edgecolor=\"black\", linewidth=0.3)\n",
        "\n",
        "    # Highlight countries that have churn data\n",
        "    highlighted = world[world[\"churn_rate\"].notnull()]\n",
        "    highlighted.plot(ax=ax, column=\"churn_rate\", cmap=\"Reds\", edgecolor=\"black\", linewidth=0.8, legend=True)\n",
        "\n",
        "    # Annotate country names and churn rates\n",
        "    for idx, row in highlighted.iterrows():\n",
        "        point = row[\"geometry\"].representative_point()\n",
        "        plt.annotate(\n",
        "            text=f\"{row['admin']} ({row['churn_rate'] * 100:.2f}%)\",\n",
        "            xy=(point.x, point.y),\n",
        "            ha=\"center\",\n",
        "            fontsize=10,\n",
        "            color=\"black\",\n",
        "            weight=\"bold\"\n",
        "        )\n",
        "\n",
        "    ax.set_xlim(-10, 30)\n",
        "    ax.set_ylim(35, 65)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Churn Rate by Geography (%)\", fontsize=18, pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "geography_distribution()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:45.393851Z",
          "iopub.execute_input": "2025-08-12T10:18:45.39411Z",
          "iopub.status.idle": "2025-08-12T10:18:48.951131Z",
          "shell.execute_reply.started": "2025-08-12T10:18:45.394092Z",
          "shell.execute_reply": "2025-08-12T10:18:48.949902Z"
        },
        "trusted": true,
        "id": "ab16soTF4-rQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# A. Age Distribution by Geography & Churn Status\n",
        "sns.boxplot(x=\"Geography\", y=\"Age\", data=df_customer_churnma, ax=ax[0, 0], hue=\"Exited\", palette=color(n_colors=2),\n",
        "            order=[\"France\", \"Germany\", \"Spain\"],)\n",
        "ax[0, 0].set_title(\"Age Distribution by Geography & Churn Status\", weight=\"bold\")\n",
        "ax[0, 0].set_xlabel(\"Geography\")\n",
        "ax[0, 0].set_ylabel(\"Age\")\n",
        "sns.despine(left=False, bottom=False, ax=ax[0, 0])\n",
        "\n",
        "# B. Balance Distribution by Geography & Churn Status\n",
        "sns.boxplot(x=\"Geography\", y=\"Balance\", data=df_customer_churnma, ax=ax[0, 1], hue=\"Exited\", palette=color(n_colors=2))\n",
        "ax[0, 1].set_title(\"Balance Distribution by Geography & Churn Status\", weight=\"bold\")\n",
        "ax[0, 1].set_xlabel(\"Geography\")\n",
        "ax[0, 1].set_ylabel(\"Balance\")\n",
        "sns.despine(left=False, bottom=False, ax=ax[0, 1])\n",
        "\n",
        "# C. Product Usage by Geography\n",
        "sns.countplot(x=\"Geography\", hue=\"NumOfProducts\", data=df_customer_churnma, ax=ax[1, 0], palette=color(n_colors=4))\n",
        "ax[1, 0].set_title(\"Product Usage by Geography\", weight=\"bold\")\n",
        "ax[1, 0].set_xlabel(\"Geography\")\n",
        "ax[1, 0].set_ylabel(\"\")\n",
        "sns.despine(left=False, bottom=False, ax=ax[1, 0])\n",
        "\n",
        "# D. Activity Status by Geography\n",
        "sns.countplot(x=\"Geography\", hue=\"IsActiveMember\", data=df_customer_churnma, ax=ax[1, 1], palette=color(n_colors=2))\n",
        "ax[1, 1].set_title(\"Activity Status by Geography\", weight=\"bold\")\n",
        "ax[1, 1].set_xlabel(\"Geography\")\n",
        "ax[1, 1].set_ylabel(\"\")\n",
        "sns.despine(left=False, bottom=False, ax=ax[1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:48.952384Z",
          "iopub.execute_input": "2025-08-12T10:18:48.952661Z",
          "iopub.status.idle": "2025-08-12T10:18:50.168808Z",
          "shell.execute_reply.started": "2025-08-12T10:18:48.952637Z",
          "shell.execute_reply": "2025-08-12T10:18:50.167425Z"
        },
        "trusted": true,
        "id": "H0kNbGzE4-rQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Age Profile**\n",
        "\n",
        "* The **median age** of churned customers in Germany is relatively high (\\~45 years), similar to France and Spain.\n",
        "* However, the **proportion of older customers** (40+) who churn in Germany is more pronounced, and older customers are more likely to leave according to earlier statistical tests.\n",
        "\n",
        "**2. Balance Levels**\n",
        "\n",
        "* Churned customers in Germany have **higher account balances** than non-churned ones.\n",
        "* This aligns with earlier findings that higher balance correlates with higher churn ‚Äî possibly due to these customers seeking better investment/interest opportunities elsewhere.\n",
        "\n",
        "**3. Product Usage**\n",
        "\n",
        "* A **large proportion of German customers** hold **only 1 product**, which is a profile linked with higher churn in the Chi-square analysis.\n",
        "* Lower product engagement often indicates weaker ties to the bank, making these customers easier to lose.\n",
        "\n",
        "**4. Activity Status**\n",
        "\n",
        "* Germany has a **smaller proportion of active members** compared to France, and inactivity is strongly associated with churn.\n",
        "* This suggests customer engagement in Germany is generally lower.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "The **higher churn rate in Germany (37.52%)** appears to be driven by a combination of:\n",
        "\n",
        "1. **Older age distribution** among churned customers.\n",
        "2. **Higher balances** among those who leave, making them attractive targets for competitors.\n",
        "3. **Lower product diversity**, with many customers holding only 1 product.\n",
        "4. **Lower engagement** (activity rates) compared to other regions."
      ],
      "metadata": {
        "id": "cSJlFLZn4-rQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Should we implement **dedicated retention campaigns** for Germany?"
      ],
      "metadata": {
        "id": "6yO8NnCc4-rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# A. Age Distribution by Geography & Churn Status\n",
        "sns.boxplot(x=\"Geography\", y=\"Balance\", data=df_customer_churnma, ax=ax, hue=\"Exited\", palette=color(n_colors=2))\n",
        "ax.set_title(\"Balance Distribution by Geography & Churn Status\", weight=\"bold\")\n",
        "ax.set_xlabel(\"Geography\")\n",
        "ax.set_ylabel(\"Balance\")\n",
        "sns.despine(left=False, bottom=False, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:50.170028Z",
          "iopub.execute_input": "2025-08-12T10:18:50.170485Z",
          "iopub.status.idle": "2025-08-12T10:18:50.469192Z",
          "shell.execute_reply.started": "2025-08-12T10:18:50.17046Z",
          "shell.execute_reply": "2025-08-12T10:18:50.468111Z"
        },
        "trusted": true,
        "id": "rrgQ3v924-rQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the **Balance Distribution by Geography & Churn Status** chart, it is clear that:\n",
        "\n",
        "* **Customers in Germany** have a **notably higher median account balance** compared to France and Spain, in both churned and non-churned groups.\n",
        "* The churn rate in Germany is also **significantly higher** (\\~37.5%) compared to France (\\~16.5%) and Spain (\\~17.2%).\n",
        "* This means there is a **greater risk of losing high-value customers** in Germany.\n",
        "\n",
        "**Business Conclusion:**\n",
        "\n",
        "* A **dedicated retention campaign** should be implemented for German customers, especially those with large account balances.\n",
        "* Campaigns may include **personalized offers, VIP customer service, and enhanced customer experiences** to reduce attrition."
      ],
      "metadata": {
        "id": "OeYL3oR04-rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do the **needs, expectations, or experiences** of female customers differ from males?"
      ],
      "metadata": {
        "id": "15LLJ8bc4-rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary table by gender\n",
        "def gender_churn_summary(df):\n",
        "    summary = df.groupby(\"Gender\").agg(\n",
        "        ChurnRate=(\"Exited\", \"mean\"),\n",
        "        Avg_Balance=(\"Balance\", \"mean\"),\n",
        "        Percent_Inactive=(\"IsActiveMember\", lambda x: (x == 0).mean()),\n",
        "        Avg_Age=(\"Age\", \"mean\"),\n",
        "        Avg_CreditScore = (\"CreditScore\", \"mean\"),\n",
        "        Avg_EstimatedSalary = (\"EstimatedSalary\", \"mean\"),\n",
        "        Count=(\"Exited\", \"count\")\n",
        "    ).reset_index()\n",
        "\n",
        "    # Format percentages for readability\n",
        "    summary[\"ChurnRate\"] = (summary[\"ChurnRate\"] * 100).round(2)\n",
        "    summary[\"Percent_Inactive\"] = (summary[\"Percent_Inactive\"] * 100).round(2)\n",
        "    summary[\"Avg_Balance\"] = summary[\"Avg_Balance\"].round(0)\n",
        "    summary[\"Avg_CreditScore\"] = summary[\"Avg_CreditScore\"].round(0)\n",
        "    summary[\"Avg_EstimatedSalary\"] = summary[\"Avg_EstimatedSalary\"].round(0)\n",
        "    summary[\"Avg_Age\"] = summary[\"Avg_Age\"].round(1)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Apply to the entire dataset\n",
        "summary_all = gender_churn_summary(df_customer_churnma)\n",
        "\n",
        "from tabulate import tabulate\n",
        "print(tabulate(summary_all, headers=\"keys\", tablefmt=\"github\", showindex=False))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:50.470041Z",
          "iopub.execute_input": "2025-08-12T10:18:50.470391Z",
          "iopub.status.idle": "2025-08-12T10:18:50.52812Z",
          "shell.execute_reply.started": "2025-08-12T10:18:50.470342Z",
          "shell.execute_reply": "2025-08-12T10:18:50.527116Z"
        },
        "trusted": true,
        "id": "KqE-4anq4-rR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gender-based Churn Insights**\n",
        "\n",
        "* **Churn Rate**: Female customers have a **significantly higher** churn rate compared to male customers (27.81% vs. 15.94%), indicating that gender is an important factor in churn behavior.\n",
        "* **Account Balance**: On average, female customers have a **slightly higher** account balance than male customers (57,661 vs. 55,921).\n",
        "* **Activity Level**: Female customers have a higher inactivity rate (52.01% vs. 48.68%), which may contribute to their higher churn rate.\n",
        "* **Other factors** (Age, CreditScore, EstimatedSalary): Relatively similar between genders."
      ],
      "metadata": {
        "id": "jWkdPnGr4-rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Should we design **products/services** better suited for female customers?"
      ],
      "metadata": {
        "id": "LI2uPgSl4-rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create Balance & Income segments (high/low based on median)\n",
        "balance_median = df_customer_churnma[\"Balance\"].median()\n",
        "income_median = df_customer_churnma[\"EstimatedSalary\"].median()\n",
        "\n",
        "df_customer_churnma[\"BalanceSegment\"] = df_customer_churnma[\"Balance\"].apply(lambda x: \"High Balance\" if x >= balance_median else \"Low Balance\")\n",
        "df_customer_churnma[\"IncomeSegment\"] = df_customer_churnma[\"EstimatedSalary\"].apply(lambda x: \"High Income\" if x >= income_median else \"Low Income\")\n",
        "\n",
        "# 2. Churn rate by activity level & gender\n",
        "churn_activity_gender = (\n",
        "    df_customer_churnma.groupby([\"IsActiveMember\", \"Gender\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 3. Churn rate by customer value (Balance) & gender\n",
        "churn_balance_gender = (\n",
        "    df_customer_churnma.groupby([\"BalanceSegment\", \"Gender\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 4. Churn rate by customer value (Income) & gender\n",
        "churn_income_gender = (\n",
        "    df_customer_churnma.groupby([\"IncomeSegment\", \"Gender\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 5. Plot the charts\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# A. Activity vs Gender\n",
        "sns.barplot(data=churn_activity_gender, x=\"IsActiveMember\", y=\"Exited\", hue=\"Gender\", ax=axes[0], palette=color(n_colors=2))\n",
        "axes[0].set_title(\"Churn Rate by Activity Level & Gender\", weight=\"bold\")\n",
        "axes[0].set_ylabel(\"Churn Rate%\")\n",
        "\n",
        "# B. Balance vs Gender\n",
        "sns.barplot(data=churn_balance_gender, x=\"BalanceSegment\", y=\"Exited\", hue=\"Gender\", ax=axes[1], palette=color(n_colors=2))\n",
        "axes[1].set_title(\"Churn Rate by Balance Segment & Gender\", weight=\"bold\")\n",
        "axes[1].set_ylabel(\"Churn Rate%\")\n",
        "\n",
        "# C. Income vs Gender\n",
        "sns.barplot(data=churn_income_gender, x=\"IncomeSegment\", y=\"Exited\", hue=\"Gender\", ax=axes[2], palette=color(n_colors=2))\n",
        "axes[2].set_title(\"Churn Rate by Income Segment & Gender\", weight=\"bold\")\n",
        "axes[2].set_ylabel(\"Churn Rate%\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:50.529033Z",
          "iopub.execute_input": "2025-08-12T10:18:50.529261Z",
          "iopub.status.idle": "2025-08-12T10:18:51.123712Z",
          "shell.execute_reply.started": "2025-08-12T10:18:50.529244Z",
          "shell.execute_reply": "2025-08-12T10:18:51.122489Z"
        },
        "trusted": true,
        "id": "_gubOkfL4-rR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Across all segments, **female customers** consistently exhibit **higher churn rates** than male customers.\n",
        "* The difference is most pronounced among:\n",
        "\n",
        "  * **Inactive members**: Female churn rate \\~37%, significantly higher than males (\\~23%).\n",
        "  * **High-balance customers**: Female churn rate \\~28% vs. male \\~16%.\n",
        "  * **High-income customers**: Female churn rate \\~29% vs. male \\~16%.\n",
        "* These segments represent **high-value customers** at greater risk of leaving.\n",
        "\n",
        "**Recommendation ‚Äì Tailored Offerings for Female Customers**\n",
        "* Design **dedicated retention programs** targeting female customers, especially in the inactive, high-balance, and high-income segments."
      ],
      "metadata": {
        "id": "AmFQu4TI4-rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do customers without credit cards share certain characteristics in Balance, Age, NumOfProducts, or IsActiveMember?"
      ],
      "metadata": {
        "id": "XRKhQ-xJ4-rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Boxplot cho Balance v√† Age\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(data=df_customer_churnma, x=\"HasCrCard\", y=\"Balance\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"Balance by HasCrCard\", weight=\"bold\")\n",
        "plt.xlabel(\"HasCrCard\")\n",
        "plt.ylabel(\"Balance\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(data=df_customer_churnma, x=\"HasCrCard\", y=\"Age\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"Age by HasCrCard\", weight=\"bold\")\n",
        "plt.xlabel(\"HasCrCard\")\n",
        "plt.ylabel(\"Age\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Barplot cho NumOfProducts v√† IsActiveMember\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "num_prod_dist = df_customer_churnma.groupby([\"HasCrCard\", \"NumOfProducts\"]).size().reset_index(name=\"Count\")\n",
        "sns.barplot(data=num_prod_dist, x=\"NumOfProducts\", y=\"Count\", hue=\"HasCrCard\", palette=color(n_colors=2))\n",
        "plt.title(\"NumOfProducts Distribution by HasCrCard\", weight=\"bold\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "active_dist = df_customer_churnma.groupby([\"HasCrCard\", \"IsActiveMember\"]).size().reset_index(name=\"Count\")\n",
        "sns.barplot(data=active_dist, x=\"IsActiveMember\", y=\"Count\", hue=\"HasCrCard\", palette=color(n_colors=2))\n",
        "plt.title(\"IsActiveMember Distribution by HasCrCard\", weight=\"bold\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:51.124672Z",
          "iopub.execute_input": "2025-08-12T10:18:51.124979Z",
          "iopub.status.idle": "2025-08-12T10:18:51.972176Z",
          "shell.execute_reply.started": "2025-08-12T10:18:51.124958Z",
          "shell.execute_reply": "2025-08-12T10:18:51.971163Z"
        },
        "trusted": true,
        "id": "pZvN8rIk4-rS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary answer to the question**\n",
        "\n",
        "> **Customers without credit cards** do not show significant differences in **Balance** or **Age** compared to those with credit cards. However, they:\n",
        ">\n",
        "> * Are less likely to have more than 2 products\n",
        "> * Have a slightly higher proportion of inactive members."
      ],
      "metadata": {
        "id": "9l-0Ujmw4-rS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do inactive customers share specific characteristics in CreditScore, Balance, Age, and NumOfProducts?"
      ],
      "metadata": {
        "id": "Px8HK45g4-rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 1. CreditScore by IsActiveMember\n",
        "sns.boxplot(data=df_customer_churnma, x=\"IsActiveMember\", y=\"CreditScore\", palette=color(n_colors=2), ax=axes[0,0])\n",
        "axes[0,0].set_title(\"CreditScore by IsActiveMember\")\n",
        "axes[0,0].set_xlabel(\"IsActiveMember\")\n",
        "axes[0,0].set_ylabel(\"CreditScore\")\n",
        "\n",
        "# 2. Balance by IsActiveMember\n",
        "sns.boxplot(data=df_customer_churnma, x=\"IsActiveMember\", y=\"Balance\", palette=color(n_colors=2), ax=axes[0,1])\n",
        "axes[0,1].set_title(\"Balance by IsActiveMember\")\n",
        "axes[0,1].set_xlabel(\"IsActiveMember\")\n",
        "axes[0,1].set_ylabel(\"Balance\")\n",
        "\n",
        "# 3. Age by IsActiveMember\n",
        "sns.boxplot(data=df_customer_churnma, x=\"IsActiveMember\", y=\"Age\", palette=color(n_colors=2), ax=axes[1,0])\n",
        "axes[1,0].set_title(\"Age by IsActiveMember\")\n",
        "axes[1,0].set_xlabel(\"IsActiveMember\")\n",
        "axes[1,0].set_ylabel(\"Age\")\n",
        "\n",
        "# 4. NumOfProducts distribution by IsActiveMember\n",
        "num_prod_dist = df_customer_churnma.groupby([\"IsActiveMember\", \"NumOfProducts\"]).size().reset_index(name=\"Count\")\n",
        "sns.barplot(data=num_prod_dist, x=\"NumOfProducts\", y=\"Count\", hue=\"IsActiveMember\", palette=color(n_colors=2), ax=axes[1,1])\n",
        "axes[1,1].set_title(\"NumOfProducts Distribution by IsActiveMember\")\n",
        "axes[1,1].set_xlabel(\"NumOfProducts\")\n",
        "axes[1,1].set_ylabel(\"Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:51.9731Z",
          "iopub.execute_input": "2025-08-12T10:18:51.973387Z",
          "iopub.status.idle": "2025-08-12T10:18:52.649615Z",
          "shell.execute_reply.started": "2025-08-12T10:18:51.973343Z",
          "shell.execute_reply": "2025-08-12T10:18:52.648428Z"
        },
        "trusted": true,
        "id": "wCXfxASa4-rV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary answer to the question**\n",
        "\n",
        "> **Inactive customers** (IsActiveMember = 0) are not significantly different from active customers in terms of **CreditScore**, **Age** and **Balance**.\n",
        "> However, they:\n",
        ">\n",
        "> * Are more concentrated in the single-product segment."
      ],
      "metadata": {
        "id": "R5D4_2oA4-rW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are customers with only 1 product typically those with lower CreditScore or lower Balance?"
      ],
      "metadata": {
        "id": "iANnwiCM4-rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(data=df_customer_churnma, x=\"NumOfProducts\", y=\"CreditScore\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"CreditScore by NumOfProducts\", weight=\"bold\")\n",
        "plt.xlabel(\"NumOfProducts\")\n",
        "plt.ylabel(\"Balance\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(data=df_customer_churnma, x=\"NumOfProducts\", y=\"Balance\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"Balance by NumOfProducts\", weight=\"bold\")\n",
        "plt.xlabel(\"NumOfProducts\")\n",
        "plt.ylabel(\"Balance\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:52.650441Z",
          "iopub.execute_input": "2025-08-12T10:18:52.650696Z",
          "iopub.status.idle": "2025-08-12T10:18:53.356386Z",
          "shell.execute_reply.started": "2025-08-12T10:18:52.650679Z",
          "shell.execute_reply": "2025-08-12T10:18:53.355443Z"
        },
        "trusted": true,
        "id": "D_5364ab4-rW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CreditScore by NumOfProducts**\n",
        "\n",
        "* Customers with **only 1 product** do not have noticeably lower CreditScores compared to other groups.\n",
        "* The median CreditScore for this group is quite similar to those with 2‚Äì4 products (\\~650‚Äì670).\n",
        "\n",
        "**2. Balance by NumOfProducts**\n",
        "\n",
        "* The **1-product** group actually has a **high median Balance**, not low ‚Äî in fact, it‚Äôs higher than the 2-product group (since the latter has many customers with a Balance of 0).\n",
        "* This indicates that having only 1 product **does not imply** weaker financial capacity.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "> Customers with only 1 product are **not** a group with low CreditScores or low Balances."
      ],
      "metadata": {
        "id": "UWXpWePi4-rW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do customers with 3‚Äì4 products have different characteristics compared to the 2-product (low churn) group?"
      ],
      "metadata": {
        "id": "UcMWA-lj4-rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only the 2-product group and the 3‚Äì4 product group\n",
        "df_compare = df_customer_churnma[df_customer_churnma[\"NumOfProducts\"].isin([2, 3, 4])].copy()\n",
        "df_compare[\"ProductGroup\"] = df_compare[\"NumOfProducts\"].apply(lambda x: \"3-4 Products\" if x >= 3 else \"2 Products\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 1. CreditScore\n",
        "sns.boxplot(data=df_compare, x=\"ProductGroup\", y=\"CreditScore\", palette=color(n_colors=2), hue=\"Exited\", ax=axes[0,0])\n",
        "axes[0,0].set_title(\"CreditScore by Product Group\", weight=\"bold\")\n",
        "\n",
        "# 2. Balance\n",
        "sns.boxplot(data=df_compare, x=\"ProductGroup\", y=\"Balance\", palette=color(n_colors=2), hue=\"Exited\", ax=axes[0,1])\n",
        "axes[0,1].set_title(\"Balance by Product Group\", weight=\"bold\")\n",
        "\n",
        "# 3. Age\n",
        "sns.boxplot(data=df_compare, x=\"ProductGroup\", y=\"Age\", palette=color(n_colors=2), hue=\"Exited\", ax=axes[1,0])\n",
        "axes[1,0].set_title(\"Age by Product Group\", weight=\"bold\")\n",
        "\n",
        "# 4. IsActiveMember distribution\n",
        "active_dist = df_compare.groupby([\"ProductGroup\", \"IsActiveMember\"]).size().reset_index(name=\"Count\")\n",
        "sns.barplot(data=active_dist, x=\"IsActiveMember\", y=\"Count\", hue=\"ProductGroup\", palette=color(n_colors=2), ax=axes[1,1])\n",
        "axes[1,1].set_title(\"IsActiveMember Distribution by Product Group\", weight=\"bold\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:53.357231Z",
          "iopub.execute_input": "2025-08-12T10:18:53.357812Z",
          "iopub.status.idle": "2025-08-12T10:18:54.3337Z",
          "shell.execute_reply.started": "2025-08-12T10:18:53.357782Z",
          "shell.execute_reply": "2025-08-12T10:18:54.332442Z"
        },
        "trusted": true,
        "id": "aGkiGoO14-rX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CreditScore**\n",
        "\n",
        "* The median CreditScore for the **3‚Äì4 products** group is almost the same as for the **2 products** group.\n",
        "* In both groups, churned customers (Exited = 1) tend to have lower CreditScores than retained customers.\n",
        "\n",
        "**2. Balance**\n",
        "\n",
        "* Both groups have similar Balance distributions, with no significant difference in the median.\n",
        "* In both groups, churned customers generally have lower Balances than those who stayed.\n",
        "\n",
        "**3. Age**\n",
        "\n",
        "* The **3‚Äì4 products** group has a **slightly higher** median age compared to the 2 products group.\n",
        "* In both groups, churned customers tend to be older than retained customers.\n",
        "\n",
        "**4. IsActiveMember**\n",
        "\n",
        "* The **3‚Äì4 products** group is predominantly **inactive** (IsActiveMember = 0), which is a stark contrast to the 2 products group.\n",
        "* This is the most notable difference between the two groups and could be the main reason for the higher churn rate in the 3‚Äì4 products group.\n",
        "\n",
        "**Summary Conclusion**\n",
        "\n",
        "> Compared to the 2 products group (low churn), the 3‚Äì4 products group does not differ much in **CreditScore** and **Balance**, and only has a slightly higher **Age**.\n",
        "> The key difference is that the 3‚Äì4 products group has an **high inactive rate**, which could explain its higher churn rate."
      ],
      "metadata": {
        "id": "sGyAorfQ4-rX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Does churn rate consistently decrease as CreditScore increases?"
      ],
      "metadata": {
        "id": "ODC3tTuR4-rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide CreditScore into ranges (bins)\n",
        "bins = [300, 500, 600, 700, 800, 900]  # adjust as needed\n",
        "labels = [\"300-499\", \"500-599\", \"600-699\", \"700-799\", \"800-899\"]\n",
        "df_customer_churnma[\"CS_group\"] = pd.cut(df_customer_churnma[\"CreditScore\"], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calculate churn rate for each group\n",
        "churn_by_group = df_customer_churnma.groupby(\"CS_group\")[\"Exited\"].mean().reset_index()\n",
        "churn_by_group[\"Exited\"] *= 100  # convert to percentage\n",
        "\n",
        "# Plot barplot\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=churn_by_group, x=\"CS_group\", y=\"Exited\",palette=color(n_colors=5))\n",
        "plt.title(\"Churn Rate by CreditScore Range\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"CreditScore Range\")\n",
        "\n",
        "# Display percentage values\n",
        "for i, v in enumerate(churn_by_group[\"Exited\"]):\n",
        "    plt.text(i, v, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:54.334664Z",
          "iopub.execute_input": "2025-08-12T10:18:54.334938Z",
          "iopub.status.idle": "2025-08-12T10:18:54.519239Z",
          "shell.execute_reply.started": "2025-08-12T10:18:54.334917Z",
          "shell.execute_reply": "2025-08-12T10:18:54.518402Z"
        },
        "trusted": true,
        "id": "diHSFyRN4-rY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Churn rate does not consistently decrease** as CreditScore increases.\n",
        "* The first two ranges (**300‚Äì499** and **500‚Äì599**) have similar churn rates (\\~22.8‚Äì22.9%).\n",
        "* There is a small drop for **600‚Äì699** (\\~20.7%) and **700‚Äì799** (\\~20.2%), but it slightly increases again for **800‚Äì899** (\\~20.3%).\n",
        "* Overall, the difference between the highest and lowest churn rate ranges is small (\\~2.7 percentage points), suggesting that CreditScore alone is not a strong predictor of churn in this dataset."
      ],
      "metadata": {
        "id": "7uXLQZZP4-rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are there notable patterns when combining CreditScore with Geography or Age?"
      ],
      "metadata": {
        "id": "w5TxzHyh4-rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(data=df_customer_churnma, x=\"Geography\", y=\"CreditScore\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"CreditScore by Geography\", weight=\"bold\")\n",
        "plt.xlabel(\"Geography\")\n",
        "plt.ylabel(\"Balance\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.scatterplot(data=df_customer_churnma, x=\"Age\", y=\"CreditScore\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"CreditScore by Age\", weight=\"bold\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"CreditScore\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:18:54.520162Z",
          "iopub.execute_input": "2025-08-12T10:18:54.52046Z",
          "iopub.status.idle": "2025-08-12T10:19:00.968658Z",
          "shell.execute_reply.started": "2025-08-12T10:18:54.520384Z",
          "shell.execute_reply": "2025-08-12T10:19:00.967726Z"
        },
        "trusted": true,
        "id": "nxW_kh1A4-rY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CreditScore by Geography** (boxplot)\n",
        "\n",
        "* The median CreditScore is **quite similar** across France, Germany, and Spain.\n",
        "* In all three countries, churned customers (Exited = 1) tend to have **slightly lower CreditScores** than retained customers, but the difference is small.\n",
        "* There is **no clear country-specific pattern** in CreditScore that could explain churn rate differences across geographies ‚Äî meaning Germany‚Äôs higher churn rate is likely driven by factors other than CreditScore.\n",
        "\n",
        "**2. CreditScore by Age** (scatter plot)\n",
        "\n",
        "* Churned customers (blue) are more concentrated in **middle-aged and older segments**, especially ages **40‚Äì65**, regardless of CreditScore.\n",
        "* There is no strong visible pattern of churn clustering in either **high** or **low** CreditScore bands ‚Äî churn appears across the entire score range.\n",
        "* Younger customers (<30) have lower churn density in general, even at lower CreditScores.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "> When combining CreditScore with Geography or Age:\n",
        ">\n",
        "> * Geography: CreditScore distribution is similar across countries; differences in churn rates between countries are likely due to other variables.\n",
        "> * Age: Churn is more prevalent in middle-aged/older customers, independent of CreditScore level. CreditScore alone does not appear to strongly drive churn in any specific age group."
      ],
      "metadata": {
        "id": "RuPKi1bv4-rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is churn rate linearly related to Age, or is it higher only in certain age groups?"
      ],
      "metadata": {
        "id": "o7PhcBnH4-rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bins = [0, 30, 45, 60, 100]\n",
        "labels = [\"<30\", \"30‚Äì45\", \"46‚Äì60\", \">60\"]\n",
        "df_customer_churnma[\"AgeGroup\"] = pd.cut(df_customer_churnma[\"Age\"], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calculate churn rate for each group\n",
        "churn_by_group = df_customer_churnma.groupby(\"AgeGroup\")[\"Exited\"].mean().reset_index()\n",
        "churn_by_group[\"Exited\"] *= 100  # convert to percentage\n",
        "\n",
        "# Plot barplot\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=churn_by_group, x=\"AgeGroup\", y=\"Exited\",palette=color(n_colors=4))\n",
        "plt.title(\"Churn Rate by AgeGroup\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"AgeGroup\")\n",
        "\n",
        "# Display percentage values\n",
        "for i, v in enumerate(churn_by_group[\"Exited\"]):\n",
        "    plt.text(i, v, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:00.969804Z",
          "iopub.execute_input": "2025-08-12T10:19:00.970108Z",
          "iopub.status.idle": "2025-08-12T10:19:01.148743Z",
          "shell.execute_reply.started": "2025-08-12T10:19:00.970086Z",
          "shell.execute_reply": "2025-08-12T10:19:01.147355Z"
        },
        "trusted": true,
        "id": "xpChvlFw4-rZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the chart you provided:\n",
        "\n",
        "* **The churn rate does not increase linearly with age.**\n",
        "* Churn is low among customers **under 30** (8.3%), rises slightly in the **30‚Äì45** group (14.9%), **spikes** in the **46‚Äì60** group (55.0%), and then **drops** in the **over 60** group (34.2%).\n",
        "* This indicates that churn is highest among **middle-aged customers (46‚Äì60 years)** rather than increasing steadily with age.\n",
        "\n",
        "**Conclusion**: The churn rate by age follows a ‚Äúpeak‚Äù pattern in the 46‚Äì60 group, then decreases for customers over 60. Retention strategies should focus on the 46‚Äì60 segment, as it is the highest-risk group."
      ],
      "metadata": {
        "id": "Qfe8_RJY4-rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Does the high-balance group churn more in all Geographies?"
      ],
      "metadata": {
        "id": "jLMNx8bp4-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Balance into High/Low based on the overall median\n",
        "bal_median = df_customer_churnma[\"Balance\"].median()\n",
        "df_customer_churnma[\"BalanceSegment\"] = np.where(df_customer_churnma[\"Balance\"] >= bal_median, \"High\", \"Low\")\n",
        "\n",
        "# Calculate churn rate\n",
        "churn_rate = (\n",
        "    df_customer_churnma.groupby([\"Geography\", \"BalanceSegment\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "churn_rate[\"Exited\"] *= 100  # convert to percentage\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=churn_rate, x=\"Geography\", y=\"Exited\", hue=\"BalanceSegment\", palette=\"Set2\")\n",
        "plt.title(\"Churn Rate by Geography and Balance Segment\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"Geography\")\n",
        "\n",
        "# Display percentage values\n",
        "for p in plt.gca().patches:\n",
        "    if p.get_height() > 0:\n",
        "        plt.text(p.get_x() + p.get_width()/2, p.get_height(),\n",
        "                 f'{p.get_height():.1f}%',\n",
        "                 ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:01.149693Z",
          "iopub.execute_input": "2025-08-12T10:19:01.150079Z",
          "iopub.status.idle": "2025-08-12T10:19:01.363715Z",
          "shell.execute_reply.started": "2025-08-12T10:19:01.150049Z",
          "shell.execute_reply": "2025-08-12T10:19:01.362892Z"
        },
        "trusted": true,
        "id": "23o92z7e4-rZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the chart you provided:\n",
        "\n",
        "* In **Germany** and **Spain**, the **high-balance group** does churn more compared to the low-balance group.\n",
        "* In **France**, the churn rate for the high-balance group is higher than zero, but the low-balance group shows almost no churn (0%), so the gap is significant there as well.\n",
        "* This suggests that across **all three geographies**, customers with higher balances tend to have a higher churn rate.\n",
        "\n",
        "**Conclusion**: Yes ‚Äî the high-balance group has a higher churn rate in all geographies, with the effect being especially pronounced in **Germany**."
      ],
      "metadata": {
        "id": "jJT2alag4-rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does the relationship between Balance and IsActiveMember affect churn?"
      ],
      "metadata": {
        "id": "Qza9ddjD4-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Balance Segment based on the median\n",
        "bal_median = df_customer_churnma[\"Balance\"].median()\n",
        "df_customer_churnma[\"BalanceSegment\"] = np.where(df_customer_churnma[\"Balance\"] >= bal_median, \"High\", \"Low\")\n",
        "\n",
        "# Calculate churn rate by BalanceSegment and IsActiveMember\n",
        "churn_data = (\n",
        "    df_customer_churnma.groupby([\"BalanceSegment\", \"IsActiveMember\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "churn_data[\"Exited\"] *= 100  # convert to percentage\n",
        "\n",
        "# Plot the chart\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=churn_data, x=\"BalanceSegment\", y=\"Exited\", hue=\"IsActiveMember\", palette=\"Set2\")\n",
        "plt.title(\"Churn Rate by Balance Segment and IsActiveMember\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"Balance Segment\")\n",
        "\n",
        "# Display percentage labels\n",
        "for p in plt.gca().patches:\n",
        "    if p.get_height() > 0:\n",
        "        plt.text(p.get_x() + p.get_width()/2, p.get_height(), f\"{p.get_height():.1f}%\",\n",
        "                 ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:01.36478Z",
          "iopub.execute_input": "2025-08-12T10:19:01.365463Z",
          "iopub.status.idle": "2025-08-12T10:19:01.573224Z",
          "shell.execute_reply.started": "2025-08-12T10:19:01.365429Z",
          "shell.execute_reply": "2025-08-12T10:19:01.572304Z"
        },
        "trusted": true,
        "id": "5CAwpRmW4-rZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that:\n",
        "\n",
        "* Within the **High Balance** group, **inactive** customers (IsActiveMember = 0) have a churn rate of **29.6%**, nearly double that of **active** customers (12.6%).\n",
        "* This indicates that **activity level** is a more critical factor than **account balance** when assessing churn risk.\n",
        "* In other words, even if customers have high balances, if they are not active, their likelihood of leaving remains high."
      ],
      "metadata": {
        "id": "svJ8a3Ln4-rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are there specific Tenure ranges (0‚Äì2 years, 7‚Äì10 years) with abnormal churn when combined with Geography or Age?"
      ],
      "metadata": {
        "id": "25V65tum4-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o TenureGroup\n",
        "bins = [0, 2, 6, 10]\n",
        "labels = [\"0-2\", \"3-6\", \"7-10\"]\n",
        "df_customer_churnma[\"TenureGroup\"] = pd.cut(df_customer_churnma[\"Tenure\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
        "\n",
        "# T·∫°o AgeGroup\n",
        "bins_age = [0, 30, 45, 60, 100]\n",
        "labels_age = [\"<30\", \"30-45\", \"46-60\", \">60\"]\n",
        "df_customer_churnma[\"AgeGroup\"] = pd.cut(df_customer_churnma[\"Age\"], bins=bins_age, labels=labels_age, right=False)\n",
        "\n",
        "# ===== 1) Churn rate theo TenureGroup √ó Geography =====\n",
        "churn_geo = (\n",
        "    df_customer_churnma.groupby([\"TenureGroup\", \"Geography\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "churn_geo[\"Exited\"] *= 100\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(data=churn_geo, x=\"TenureGroup\", y=\"Exited\", hue=\"Geography\", palette=color(n_colors=3))\n",
        "plt.title(\"Churn Rate by Tenure Group and Geography\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"Tenure Group\")\n",
        "for p in plt.gca().patches:\n",
        "    if p.get_height() > 0:\n",
        "        plt.text(p.get_x() + p.get_width()/2, p.get_height(), f\"{p.get_height():.1f}%\",\n",
        "                 ha=\"center\", va=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===== 2) Churn rate theo TenureGroup √ó AgeGroup =====\n",
        "churn_age = (\n",
        "    df_customer_churnma.groupby([\"TenureGroup\", \"AgeGroup\"])[\"Exited\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "churn_age[\"Exited\"] *= 100\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(data=churn_age, x=\"TenureGroup\", y=\"Exited\", hue=\"AgeGroup\", palette=color(n_colors=4))\n",
        "plt.title(\"Churn Rate by Tenure Group and Age Group\", weight=\"bold\")\n",
        "plt.ylabel(\"Churn Rate (%)\")\n",
        "plt.xlabel(\"Tenure Group\")\n",
        "for p in plt.gca().patches:\n",
        "    if p.get_height() > 0:\n",
        "        plt.text(p.get_x() + p.get_width()/2, p.get_height(), f\"{p.get_height():.1f}%\",\n",
        "                 ha=\"center\", va=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:01.574164Z",
          "iopub.execute_input": "2025-08-12T10:19:01.574412Z",
          "iopub.status.idle": "2025-08-12T10:19:02.143209Z",
          "shell.execute_reply.started": "2025-08-12T10:19:01.574389Z",
          "shell.execute_reply": "2025-08-12T10:19:02.141875Z"
        },
        "trusted": true,
        "id": "IBMKvXAv4-rZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For **Geography**, both **0‚Äì2 years** and **7‚Äì10 years** Tenure groups show no significant churn differences across countries ‚Äî the pattern is fairly stable, with Germany consistently having higher churn.\n",
        "* For **Age**, the **46‚Äì60** and **>60** age groups have high churn regardless of Tenure length, so there‚Äôs no specific Tenure group that stands out as ‚Äúunusual‚Äù when combined with Age.\n",
        "\n",
        "**In summary**: <br>\n",
        "**There is no clear evidence of an unusual Tenure group when combined with Geography or Age** ‚Äî churn seems to be mainly driven by Age and Geography themselves."
      ],
      "metadata": {
        "id": "z7i8_zqC4-ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is there any relationship between EstimatedSalary and other variables (Balance, CreditScore) that helps explain churn?"
      ],
      "metadata": {
        "id": "gGAH-ORu4-ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.scatterplot(data=df_customer_churnma, x=\"EstimatedSalary\", y=\"CreditScore\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"EstimatedSalary by CreditScore\", weight=\"bold\")\n",
        "plt.xlabel(\"EstimatedSalary\")\n",
        "plt.ylabel(\"CreditScore\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.scatterplot(data=df_customer_churnma, x=\"EstimatedSalary\", y=\"Balance\", palette=color(n_colors=2), hue=\"Exited\")\n",
        "plt.title(\"EstimatedSalary by Balance\", weight=\"bold\")\n",
        "plt.xlabel(\"EstimatedSalary\")\n",
        "plt.ylabel(\"Balance\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:02.144198Z",
          "iopub.execute_input": "2025-08-12T10:19:02.14448Z",
          "iopub.status.idle": "2025-08-12T10:19:16.268144Z",
          "shell.execute_reply.started": "2025-08-12T10:19:02.144458Z",
          "shell.execute_reply": "2025-08-12T10:19:16.266701Z"
        },
        "trusted": true,
        "id": "khiwq5Oa4-ra"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **EstimatedSalary vs CreditScore**: The data points are evenly distributed, with no clear trend. Both churned and non-churned customers are spread across all salary levels and credit scores.\n",
        "* **EstimatedSalary vs Balance**: Similarly, there is no strong correlation; the distribution is scattered and uniform, with no distinct clusters for churned customers.\n",
        "\n",
        "**Conclusion**: <br>\n",
        "**There is no significant relationship between EstimatedSalary and either Balance or CreditScore that explains churn**."
      ],
      "metadata": {
        "id": "_ZOpKDrv4-ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Data Preprocessing</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Data Preprocessing\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "pqqfVcC64-ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "uM98cqJw4-ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit Utilization\n",
        "df_train[\"CreditUtilization\"] = df_train[\"Balance\"] / df_train[\"EstimatedSalary\"]\n",
        "df_test[\"CreditUtilization\"] = df_test[\"Balance\"] / df_test[\"EstimatedSalary\"]\n",
        "\n",
        "# CreditScore per Age\n",
        "df_train[\"CreditScorePerAge\"] = df_train[\"CreditScore\"] / df_train[\"Age\"]\n",
        "df_test[\"CreditScorePerAge\"] = df_test[\"CreditScore\"] / df_test[\"Age\"]\n",
        "\n",
        "# HighBalance_Inactive\n",
        "bal_median_train = df_train[\"Balance\"].median()\n",
        "bal_median_test = df_test[\"Balance\"].median()\n",
        "df_train[\"HighBalance_Inactive\"] = ((df_train[\"Balance\"] >= bal_median_train) & (df_train[\"IsActiveMember\"] == 0)).astype(int)\n",
        "df_test[\"HighBalance_Inactive\"] = ((df_test[\"Balance\"] >= bal_median_test) & (df_test[\"IsActiveMember\"] == 0)).astype(int)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:16.26955Z",
          "iopub.execute_input": "2025-08-12T10:19:16.269926Z",
          "iopub.status.idle": "2025-08-12T10:19:16.295204Z",
          "shell.execute_reply.started": "2025-08-12T10:19:16.269899Z",
          "shell.execute_reply": "2025-08-12T10:19:16.294157Z"
        },
        "trusted": true,
        "id": "CVH_OIGk4-ra"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:green;'><b>Distribution of CreditUtilization by Exited</b></h2>\"))\n",
        "plot_numerical_distribution_by_Exited(feature=\"CreditUtilization\", df_train=df_train, target_feature=\"Exited\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:16.296479Z",
          "iopub.execute_input": "2025-08-12T10:19:16.29685Z",
          "iopub.status.idle": "2025-08-12T10:19:17.029149Z",
          "shell.execute_reply.started": "2025-08-12T10:19:16.296828Z",
          "shell.execute_reply": "2025-08-12T10:19:17.02797Z"
        },
        "trusted": true,
        "id": "9LJ0KAuq4-ra"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:green;'><b>Distribution of CreditScorePerAge by Exited</b></h2>\"))\n",
        "plot_numerical_distribution_by_Exited(feature=\"CreditScorePerAge\", df_train=df_train, target_feature=\"Exited\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:17.030456Z",
          "iopub.execute_input": "2025-08-12T10:19:17.030722Z",
          "iopub.status.idle": "2025-08-12T10:19:17.794313Z",
          "shell.execute_reply.started": "2025-08-12T10:19:17.030701Z",
          "shell.execute_reply": "2025-08-12T10:19:17.793182Z"
        },
        "trusted": true,
        "id": "rnCa9MPv4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bivariate_percent_plot(cat=\"HighBalance_Inactive\", df=df_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:17.795314Z",
          "iopub.execute_input": "2025-08-12T10:19:17.795686Z",
          "iopub.status.idle": "2025-08-12T10:19:18.376798Z",
          "shell.execute_reply.started": "2025-08-12T10:19:17.79566Z",
          "shell.execute_reply": "2025-08-12T10:19:18.375911Z"
        },
        "trusted": true,
        "id": "ocv3n-ks4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CreditUtilization` <br>\n",
        "* There is a statistically significant difference in credit utilization between customers who churned and those who did not (p-value ‚âà 0).\n",
        "* The churn group has a higher median credit utilization  (0.689 vs. 0).\n",
        "\n",
        "-> This indicates that the exited group has a higher level of credit compared to the retained group.\n",
        "\n",
        "`CreditScorePerAge` <br>\n",
        "* There is a statistically significant difference in CreditScorePerAge between the two groups, with the retained group having a higher CreditScorePerAge than the exited group.\n",
        "\n",
        "`HighBalance_Inactive` <br>\n",
        "* There is a significant association between `HighBalance_Inactive` and churn. Customers with high account balances but inactive status churn at a much higher rate than expected."
      ],
      "metadata": {
        "id": "jtldVFrS4-rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature                   | Type        | Statistical Test Used | Relationship with Exited | Summary                                                                                                 |\n",
        "| ------------------------- | ----------- | --------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------- |\n",
        "| **Geography**             | Categorical | Chi-Square Test       | Significant              | Customers from **Germany** are more likely to churn, **France** and **Spain** less likely to churn.     |\n",
        "| **Gender**                | Categorical | Chi-Square Test       | Significant              | **Female** customers have a higher churn rate than males.                                               |\n",
        "| **HasCrCard**             | Categorical | Chi-Square Test       | Significant              | Customers **without a credit card** churn more than expected, those **with** churn less.                |\n",
        "| **IsActiveMember**        | Categorical | Chi-Square Test       | Significant              | **Inactive** customers are more likely to churn.                                                        |\n",
        "| **NumOfProducts**         | Categorical | Chi-Square Test       | Significant              | Customers with **1, 3, or 4 products** have higher-than-expected churn.                                 |\n",
        "| **HighBalance\\_Inactive** | Categorical | Chi-Square Test       | Significant              | Customers with **high account balances but inactive status** churn at a much higher rate than expected. |\n",
        "| **CreditScore**           | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | Non-churned customers have slightly **higher median credit scores** (653 vs. 646).                      |\n",
        "| **CreditUtilization**     | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | Churned customers have a **higher median credit utilization** (0.689 vs. 0).                            |\n",
        "| **CreditScorePerAge**     | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | Non-churned customers have a **higher median CreditScorePerAge** than churned customers.                |\n",
        "| **Age**                   | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | Churned customers tend to be **older** (median 45 vs. 36).                                              |\n",
        "| **Balance**               | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | Churned customers have a **notably higher median balance** (109,344 vs. 92,063).                        |\n",
        "| **Tenure**                | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | The distribution of Tenure between the two groups **differs significantly** in a statistical sense.     |\n",
        "| **EstimatedSalary**       | Numerical   | Mann‚ÄìWhitney U Test   | Significant              | The churn group has a **higher median estimated salary**.                                               |"
      ],
      "metadata": {
        "id": "lbdZG42Z4-rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Skewness"
      ],
      "metadata": {
        "id": "y7ngeTVU4-rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\", \"CreditUtilization\", \"CreditScorePerAge\"]\n",
        "skew_feature_train, skew_train_df = check_skewness(data=df_train, dataset_name=\"Train Data\",\n",
        "                                                   numerical_features=num_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:18.377705Z",
          "iopub.execute_input": "2025-08-12T10:19:18.378043Z",
          "iopub.status.idle": "2025-08-12T10:19:18.397352Z",
          "shell.execute_reply.started": "2025-08-12T10:19:18.378021Z",
          "shell.execute_reply": "2025-08-12T10:19:18.396379Z"
        },
        "trusted": true,
        "id": "4Y-yMGOC4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "skew_feature_test, skew_test_df = check_skewness(data=df_test, dataset_name=\"Test Data\",\n",
        "                                                 numerical_features=num_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:18.398007Z",
          "iopub.execute_input": "2025-08-12T10:19:18.398198Z",
          "iopub.status.idle": "2025-08-12T10:19:18.41979Z",
          "shell.execute_reply.started": "2025-08-12T10:19:18.398182Z",
          "shell.execute_reply": "2025-08-12T10:19:18.418714Z"
        },
        "trusted": true,
        "id": "39wfTSGR4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "def handle_skewed_features(\n",
        "    df,\n",
        "    zero_threshold=0.9,\n",
        "    skew_threshold=0.5,\n",
        "    num_features=None,\n",
        "    exclude_cols=None\n",
        "\n",
        "):\n",
        "    \"\"\"\n",
        "    Handle skewed numerical features by applying appropriate transformations,\n",
        "    *forcing* certain columns to be transformed even if they don't exceed skew_threshold.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas.DataFrame\n",
        "    - zero_threshold: float (default=0.9)\n",
        "    - skew_threshold: float (default=0.5)\n",
        "    - num_features: list of numerical columns to consider\n",
        "    - exclude_cols: list of columns to skip entirely\n",
        "    - dataset: Name of dataset\n",
        "\n",
        "    Returns:\n",
        "    - df: transformed DataFrame\n",
        "    - transformed_cols: list of new feature names\n",
        "    - high_zero_cols: list of sparse features (> zero_threshold)\n",
        "    - skewed_cols: list of auto‚Äëdetected skewed features\n",
        "    - pt_dict: dict mapping each YJ‚Äëtransformed col ‚Üí its PowerTransformer\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    if num_features is None:\n",
        "        raise ValueError(\"`num_features` must be provided\")\n",
        "    if exclude_cols is None:\n",
        "        exclude_cols = []\n",
        "\n",
        "\n",
        "    # 1) pick the numeric cols to scan\n",
        "    numerical_cols = [c for c in num_features if c not in exclude_cols]\n",
        "\n",
        "    # 2) detect ultra‚Äësparse\n",
        "    zero_ratios = (df[numerical_cols] == 0).sum() / len(df)\n",
        "    high_zero_cols = zero_ratios[zero_ratios > zero_threshold].index.tolist()\n",
        "\n",
        "    # 3) compute skew\n",
        "    skew_vals = df[numerical_cols].apply(lambda s: skew(s.dropna()))\n",
        "    auto_skewed = skew_vals[abs(skew_vals) > skew_threshold].index.tolist()\n",
        "\n",
        "    # 4) union these with your forced list\n",
        "    to_transform = list(set(auto_skewed))\n",
        "\n",
        "    transformed_cols = []\n",
        "    dropped_cols     = []\n",
        "\n",
        "    for col in to_transform:\n",
        "        # if it's sparse ‚Üí binary+log\n",
        "        if col in high_zero_cols:\n",
        "            df[f\"Has_{col}\"] = (df[col] > 0).astype(int)\n",
        "            df[f\"Log_{col}\"] = df[col].map(lambda x: np.log1p(x) if x > 0 else 0)\n",
        "            transformed_cols += [f\"Has_{col}\", f\"Log_{col}\"]\n",
        "            dropped_cols.append(col)\n",
        "        # if it's discrete small‚Äëcardinality, skip transform but keep\n",
        "        elif df[col].nunique() <= 5:\n",
        "            # do nothing (we still keep raw col in df)\n",
        "            print(\"AAA\")\n",
        "            continue\n",
        "        # otherwise apply Yeo‚ÄëJohnson\n",
        "        else:\n",
        "            pt = PowerTransformer(method=\"yeo-johnson\")\n",
        "            arr = df[[col]].values  # shape (n,1)\n",
        "            df[f\"PT_{col}\"] = pt.fit_transform(arr)\n",
        "            transformed_cols.append(f\"PT_{col}\")\n",
        "            dropped_cols.append(col)\n",
        "\n",
        "    # drop originals for any column we did transform\n",
        "    df.drop(columns=dropped_cols, inplace=True)\n",
        "\n",
        "    return df, transformed_cols, high_zero_cols, auto_skewed"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:18.420927Z",
          "iopub.execute_input": "2025-08-12T10:19:18.421165Z",
          "iopub.status.idle": "2025-08-12T10:19:18.432094Z",
          "shell.execute_reply.started": "2025-08-12T10:19:18.421146Z",
          "shell.execute_reply": "2025-08-12T10:19:18.431029Z"
        },
        "trusted": true,
        "id": "4r45axWg4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_df, transformed_columns, sparse_columns, skewed_columns = handle_skewed_features(df=df_train, num_features=skew_feature_train)\n",
        "num_features = [\"CreditScore\", \"PT_Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\", \"PT_CreditUtilization\", \"PT_CreditScorePerAge\"]\n",
        "skew_feature_train, skew_train_df = check_skewness(data=processed_train_df, dataset_name=\"Train Data\", numerical_features=num_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:18.433352Z",
          "iopub.execute_input": "2025-08-12T10:19:18.433865Z",
          "iopub.status.idle": "2025-08-12T10:19:18.929405Z",
          "shell.execute_reply.started": "2025-08-12T10:19:18.433832Z",
          "shell.execute_reply": "2025-08-12T10:19:18.927931Z"
        },
        "trusted": true,
        "id": "RciliGZ-4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "processed_test_df, transformed_columns_test, sparse_columns_test, skewed_columns_test = handle_skewed_features(df=df_test, num_features=skew_feature_test)\n",
        "skew_feature_test, skew_test_df = check_skewness(data=processed_test_df, numerical_features=num_features, dataset_name= \"Test data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:18.930679Z",
          "iopub.execute_input": "2025-08-12T10:19:18.930912Z",
          "iopub.status.idle": "2025-08-12T10:19:19.305698Z",
          "shell.execute_reply.started": "2025-08-12T10:19:18.930893Z",
          "shell.execute_reply": "2025-08-12T10:19:19.304607Z"
        },
        "trusted": true,
        "id": "CR1FiTZS4-rb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from the Skewness Table (`processed_combined_df` and `processed_test_df`):**\n",
        "\n",
        "üî¥ **Skewed**:\n",
        "\n",
        "* The features `CreditUtilization`, `CreditScorePerAge`, `Age` exhibit skewness.\n",
        "\n",
        "‚úÖ **Approximately Symmetric**:\n",
        "\n",
        "* Several features, such as:\n",
        "\n",
        "  * `PT_CreditScorePerAge `, `PT_Age` and `PT_CreditUtilization` close to zero.\n",
        "  * This indicates that **Yeo-Johnson transformation was effective** for this feature."
      ],
      "metadata": {
        "id": "OLH5ZpYA4-rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-check Outlier"
      ],
      "metadata": {
        "id": "vmee8qVr4-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checking_outlier(list_feature=num_features, df=processed_train_df, dataset_name=\"Training data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.306836Z",
          "iopub.execute_input": "2025-08-12T10:19:19.307155Z",
          "iopub.status.idle": "2025-08-12T10:19:19.381679Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.307133Z",
          "shell.execute_reply": "2025-08-12T10:19:19.380765Z"
        },
        "trusted": true,
        "id": "EaingfQs4-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checking_outlier(list_feature=num_features, df=processed_test_df, dataset_name=\"Test data\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.382787Z",
          "iopub.execute_input": "2025-08-12T10:19:19.383033Z",
          "iopub.status.idle": "2025-08-12T10:19:19.438518Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.383017Z",
          "shell.execute_reply": "2025-08-12T10:19:19.437616Z"
        },
        "trusted": true,
        "id": "_8K4ZSOf4-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight**\n",
        "\n",
        "***Both the training and test datasets contain outliers in four features: `CreditScore`, `PT_Age`, `PT_CreditScorePerAge`. We will use RobustScaler to reduce the impact of these outliers.***"
      ],
      "metadata": {
        "id": "UIWsySFe4-rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Test Set\n",
        "\n",
        "Suppose we chatted with experts who told us that the **EstimatedSalary** is a very important attribute to predict **Exited**. We may want to ensure that the test set is representative of the various categories of **EstimatedSalary** in the whole dataset. Since the **EstimatedSalary** is a continuous numerical attribute, we first need to create an category attribute."
      ],
      "metadata": {
        "id": "82Rz-_z34-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_df[\"EstimatedSalary_Cat\"] = pd.qcut(processed_train_df[\"EstimatedSalary\"],\n",
        "                                              q=5,\n",
        "                                              labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data=processed_train_df, x=\"EstimatedSalary_Cat\", color=\"lightblue\", edgecolor=\"black\")\n",
        "\n",
        "plt.title(\"Distribution of EstimatedSalary_Cat\", fontsize=14)\n",
        "plt.xlabel(\"EstimatedSalary_Cat\", fontsize=12)\n",
        "plt.ylabel(\"\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.439469Z",
          "iopub.execute_input": "2025-08-12T10:19:19.439818Z",
          "iopub.status.idle": "2025-08-12T10:19:19.710793Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.439794Z",
          "shell.execute_reply": "2025-08-12T10:19:19.709717Z"
        },
        "trusted": true,
        "id": "3HePePKy4-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(processed_train_df, processed_train_df[\"EstimatedSalary_Cat\"]):\n",
        "    start_train_set = processed_train_df.iloc[train_index]\n",
        "    start_test_set = processed_train_df.iloc[test_index]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.711957Z",
          "iopub.execute_input": "2025-08-12T10:19:19.71238Z",
          "iopub.status.idle": "2025-08-12T10:19:19.792338Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.712323Z",
          "shell.execute_reply": "2025-08-12T10:19:19.791324Z"
        },
        "trusted": true,
        "id": "XslbQFBg4-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale and Ecode"
      ],
      "metadata": {
        "id": "ngQXz2uc4-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we should remove the EstimatedSalary_Cat attribute so the data is back to its original state:\n",
        "for set_ in (start_train_set, start_test_set):\n",
        "    set_.drop(\"EstimatedSalary_Cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.793265Z",
          "iopub.execute_input": "2025-08-12T10:19:19.793652Z",
          "iopub.status.idle": "2025-08-12T10:19:19.806394Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.793629Z",
          "shell.execute_reply": "2025-08-12T10:19:19.805311Z"
        },
        "trusted": true,
        "id": "k0fsMe_A4-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_new = start_train_set.drop(\"Exited\", axis=1)\n",
        "df_train_label_new = start_train_set[\"Exited\"].copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.807664Z",
          "iopub.execute_input": "2025-08-12T10:19:19.808009Z",
          "iopub.status.idle": "2025-08-12T10:19:19.823512Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.807988Z",
          "shell.execute_reply": "2025-08-12T10:19:19.822507Z"
        },
        "trusted": true,
        "id": "-Jj2f3344-rc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "list_feature_num_robust = [\"CreditScore\",\"PT_Age\", \"PT_CreditScorePerAge\"]\n",
        "list_feature_num_stand = [\"Tenure\", \"Balance\", \"EstimatedSalary\", \"PT_CreditUtilization\"]\n",
        "list_feature_cat_onehot = [\"Geography\", \"Gender\", \"NumOfProducts\"]\n",
        "list_feature_cat_keep = [\"HasCrCard\", \"IsActiveMember\", \"HighBalance_Inactive\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.824417Z",
          "iopub.execute_input": "2025-08-12T10:19:19.824735Z",
          "iopub.status.idle": "2025-08-12T10:19:19.833071Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.824707Z",
          "shell.execute_reply": "2025-08-12T10:19:19.831888Z"
        },
        "trusted": true,
        "id": "cZFa6VPD4-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_robust_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", RobustScaler())\n",
        "])\n",
        "\n",
        "num_stand_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_onehot_transformer = Pipeline(steps=[\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "cat_keep_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.834257Z",
          "iopub.execute_input": "2025-08-12T10:19:19.834677Z",
          "iopub.status.idle": "2025-08-12T10:19:19.859582Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.834645Z",
          "shell.execute_reply": "2025-08-12T10:19:19.858332Z"
        },
        "trusted": true,
        "id": "NPdTFrBm4-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num_robust\", num_robust_transformer, list_feature_num_robust),\n",
        "    (\"num_standard\", num_stand_transformer, list_feature_num_stand),\n",
        "    (\"cat_onehot\", cat_onehot_transformer, list_feature_cat_onehot),\n",
        "    (\"cat_keep\", cat_keep_transformer, list_feature_cat_keep),\n",
        "])\n",
        "\n",
        "preprocessor.fit(df_train_new)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:19.866523Z",
          "iopub.execute_input": "2025-08-12T10:19:19.867018Z",
          "iopub.status.idle": "2025-08-12T10:19:20.14103Z",
          "shell.execute_reply.started": "2025-08-12T10:19:19.866991Z",
          "shell.execute_reply": "2025-08-12T10:19:20.139834Z"
        },
        "trusted": true,
        "id": "MwYF_2cr4-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_new_prepared = preprocessor.transform(df_train_new)\n",
        "list_feature_prepared = preprocessor.get_feature_names_out().tolist()\n",
        "list_feature_prepared"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:20.141987Z",
          "iopub.execute_input": "2025-08-12T10:19:20.142808Z",
          "iopub.status.idle": "2025-08-12T10:19:20.287103Z",
          "shell.execute_reply.started": "2025-08-12T10:19:20.142774Z",
          "shell.execute_reply": "2025-08-12T10:19:20.285602Z"
        },
        "trusted": true,
        "id": "c7CzpY_84-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Define Metric</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Define Metric\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "LmbicwSd4-rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric        | Definition                                                  | Meaning in Attrition Context                                          |\n",
        "| ------------- | ----------------------------------------------------------- | --------------------------------------------------------------------- |\n",
        "| **Recall**    | $\\frac{TP}{TP + FN}$                                        | **Most important** ‚Äì how many true leavers you can catch              |\n",
        "| **Precision** | $\\frac{TP}{TP + FP}$                                        | Among predicted leavers, how many are actually correct                |\n",
        "| **Accuracy**  | $\\frac{TP + TN}{Total}$                                     | Can be misleading with imbalanced data (e.g., <20% attrition)         |\n",
        "| **F1-score**  | $\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$ | Balanced trade-off between Precision and Recall                       |\n",
        "| **AUC-ROC**   | Area under ROC Curve                                        | Measures ability to distinguish leavers vs. stayers at all thresholds |"
      ],
      "metadata": {
        "id": "TwBiiqE84-rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Comparison Models</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Comparison Models\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "LMrwPjUE4-rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_1 = df_train_label_new.sum()\n",
        "class_0 = len(df_train_label_new) - class_1\n",
        "scale_pos_weight = class_0 / class_1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:20.288305Z",
          "iopub.execute_input": "2025-08-12T10:19:20.288797Z",
          "iopub.status.idle": "2025-08-12T10:19:20.321861Z",
          "shell.execute_reply.started": "2025-08-12T10:19:20.288739Z",
          "shell.execute_reply": "2025-08-12T10:19:20.294052Z"
        },
        "trusted": true,
        "id": "pcc6Rdlr4-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "seed = 42\n",
        "max_iter = 50000\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "models = [\n",
        "    LinearSVC(max_iter=max_iter, random_state=seed, class_weight=\"balanced\"),\n",
        "    SVC(kernel=\"rbf\", random_state=seed, class_weight=\"balanced\"),\n",
        "    KNeighborsClassifier(metric=\"minkowski\", p=2, n_neighbors=5),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(solver=\"liblinear\", max_iter=max_iter, random_state=seed, class_weight=\"balanced\"),\n",
        "    DecisionTreeClassifier(max_depth=5, random_state=seed, class_weight=\"balanced\"),\n",
        "    RandomForestClassifier(n_estimators=100, random_state=seed, class_weight=\"balanced\"),\n",
        "    ExtraTreesClassifier(random_state=seed, class_weight=\"balanced\"),\n",
        "    AdaBoostClassifier(random_state=seed),\n",
        "    XGBClassifier(\n",
        "        n_estimators=2000, max_depth=4, eval_metric=\"logloss\", random_state=seed,\n",
        "        min_child_weight=2, gamma=0.9, subsample=0.8, colsample_bytree=0.8,\n",
        "        objective=\"binary:logistic\", nthread=-1, scale_pos_weight=scale_pos_weight\n",
        "    ),\n",
        "    MLPClassifier(max_iter=max_iter, random_state=seed),\n",
        "    GradientBoostingClassifier(random_state=seed),\n",
        "    RidgeClassifier(alpha=1.0, random_state=seed, max_iter=max_iter, class_weight=\"balanced\"),\n",
        "    RidgeClassifierCV(alphas=[0.1, 0.5, 1.0], cv=kfold, class_weight=\"balanced\"),\n",
        "    CatBoostClassifier(verbose=0, random_seed=seed, auto_class_weights=\"Balanced\"),\n",
        "    BaggingClassifier(random_state=seed),\n",
        "    HistGradientBoostingClassifier(random_state=seed, class_weight=\"balanced\", max_iter=max_iter)\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-08-12T10:19:20.322945Z",
          "iopub.execute_input": "2025-08-12T10:19:20.323331Z",
          "iopub.status.idle": "2025-08-12T10:19:20.950297Z",
          "shell.execute_reply.started": "2025-08-12T10:19:20.323297Z",
          "shell.execute_reply": "2025-08-12T10:19:20.949329Z"
        },
        "trusted": true,
        "id": "xDx-EiXf4-rd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_baseline_results(models=models, X=df_train_new_prepared, y=df_train_label_new,\n",
        "                              metric=\"roc_auc\", cv=kfold, plot_result=False):\n",
        "    entries = []\n",
        "    for model in models:\n",
        "        model_name = getattr(model, \"name\", model.__class__.__name__)\n",
        "        scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
        "        for fold_idx, s in enumerate(scores, start=1):\n",
        "            entries.append((model_name, fold_idx, s))\n",
        "\n",
        "    cv_df = pd.DataFrame(entries, columns=[\"model_name\", \"fold_id\", \"score\"])\n",
        "\n",
        "    summary = (cv_df.groupby(\"model_name\")[\"score\"]\n",
        "                    .agg(Mean=\"mean\", Std=\"std\", N=\"size\")\n",
        "                    .sort_values(\"Mean\", ascending=False))\n",
        "\n",
        "    if plot_result:\n",
        "        order = summary.index.tolist()\n",
        "        plt.figure(figsize=(18, 8))\n",
        "        sns.barplot(data=cv_df, x=\"model_name\", y=\"score\", order=order, errorbar=(\"sd\"), palette=\"viridis\")\n",
        "        title_metric = metric.upper() if isinstance(metric, str) else \"Score\"\n",
        "        nfolds = getattr(cv, \"n_splits\", \"CV\")\n",
        "        plt.title(f\"Baseline {title_metric} using {nfolds}-fold cross-validation\", fontsize=14, weight=\"bold\", pad=20)\n",
        "        plt.xlabel(\"Model\"); plt.ylabel(title_metric)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return summary\n",
        "\n",
        "generate_baseline_results(plot_result = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T03:07:38.996505Z",
          "iopub.status.busy": "2025-08-12T03:07:38.995574Z",
          "iopub.status.idle": "2025-08-12T03:46:03.485117Z",
          "shell.execute_reply": "2025-08-12T03:46:03.484359Z",
          "shell.execute_reply.started": "2025-08-12T03:07:38.996482Z"
        },
        "trusted": true,
        "id": "mBvePtND4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Hyperparameter tuning</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Hyperparameter tuning\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "S3vs2Bx34-re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shap_plot(model, X_test, list_feature, type = None):\n",
        "     # https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137/\n",
        "    if hasattr(X_test, \"toarray\"):\n",
        "        X_test = X_test.toarray()\n",
        "    X_test_sample = pd.DataFrame(X_test, columns=list_feature)\n",
        "    explainer = shap.Explainer(model.predict, X_test_sample)\n",
        "    shap_values = explainer(X_test_sample)\n",
        "    if type ==\"bar\":\n",
        "        shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "        shap_df = pd.DataFrame({\"feature\": X_test_sample.columns, \"importance\": shap_importance})\n",
        "        shap_df = shap_df.sort_values(\"importance\", ascending=False).head(20)\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.barplot(x=shap_df[\"importance\"], y=shap_df[\"feature\"], palette=\"viridis\", order=shap_df[\"feature\"])\n",
        "        plt.xlabel(\"mean(|SHAP value|)\")\n",
        "        plt.title(\"SHAP Feature Importance\", fontsize=14, weight=\"bold\", pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        shap.summary_plot(shap_values, X_test_sample)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:15:14.460386Z",
          "iopub.status.busy": "2025-08-12T05:15:14.459789Z",
          "iopub.status.idle": "2025-08-12T05:15:14.46597Z",
          "shell.execute_reply": "2025-08-12T05:15:14.465058Z",
          "shell.execute_reply.started": "2025-08-12T05:15:14.460363Z"
        },
        "trusted": true,
        "id": "WZCZprNc4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ROC_confusionMatrix(estimator, X_val, y_val, figsize):\n",
        "    y_pred_prob = estimator.predict_proba(X_val)[:, 1]  # Probability of positive class\n",
        "    y_pred = estimator.predict(X_val)\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=2, sharey=False, figsize=figsize)\n",
        "\n",
        "    # Plot 1\n",
        "    # Calculate ROC\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
        "    rocScore = roc_auc_score(y_val, y_pred_prob)\n",
        "\n",
        "    ax[0, 0].plot(fpr, tpr, label=f\"{estimator.__class__.__name__} (AUC = {rocScore:.2f})\")\n",
        "    ax[0, 0].plot([0, 1], [0, 1], \"b--\")\n",
        "    ax[0, 0].set_xlabel(\"False Positive Rate\")\n",
        "    ax[0, 0].set_ylabel(\"True Positive Rate\")\n",
        "    ax[0, 0].set_title(f\"ROC ({estimator.__class__.__name__})\", fontsize=14, weight=\"bold\", pad=20)\n",
        "    ax[0, 0].legend()\n",
        "\n",
        "    # Plot 2\n",
        "    confusionMatrix = confusion_matrix(y_val, y_pred)\n",
        "    sns.heatmap(confusionMatrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0, 1])\n",
        "    ax[0, 1].set_title(f\"Confusion Matrix ({estimator.__class__.__name__})\", fontsize=14, weight=\"bold\", pad=20)\n",
        "    ax[0, 1].set_xlabel(\"Prediction\")\n",
        "    ax[0, 1].set_ylabel(\"Actual\")\n",
        "\n",
        "    # plot 3\n",
        "    precision, recall, thresholds_pr = precision_recall_curve(y_val, y_pred_prob)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    ax[1, 0].plot(recall, precision, label=f\"PR Curve (AUC = {pr_auc:.3f})\")\n",
        "    ax[1, 0].set_xlabel(\"Recall\")\n",
        "    ax[1, 0].set_ylabel(\"Precision\")\n",
        "    ax[1, 0].set_title(\"Precision-Recall Curve\", fontsize=14, weight=\"bold\", pad=20)\n",
        "    ax[1, 0].legend()\n",
        "\n",
        "    ax.flat[-1].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(classification_report(y_val, y_pred))\n",
        "    return rocScore"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:15:21.186743Z",
          "iopub.status.busy": "2025-08-12T05:15:21.186052Z",
          "iopub.status.idle": "2025-08-12T05:15:21.194482Z",
          "shell.execute_reply": "2025-08-12T05:15:21.193681Z",
          "shell.execute_reply.started": "2025-08-12T05:15:21.186722Z"
        },
        "trusted": true,
        "id": "0n1Ee6Ht4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_train, X_val, y_train, y_val, figsize = (15, 6), show_shap_plot = False):\n",
        "    print(f\"Evaluating {model.__class__.__name__}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    rocScore = plot_ROC_confusionMatrix(estimator = model, X_val = X_val, y_val = y_val, figsize = figsize)\n",
        "    if show_shap_plot:\n",
        "        shap_sample = X_val.iloc[:200] if isinstance(X_val, pd.DataFrame) else X_val[:200]\n",
        "        shap_plot(model=model, X_test=shap_sample, list_feature=list_feature_prepared)\n",
        "    return rocScore"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:15:54.288598Z",
          "iopub.status.busy": "2025-08-12T05:15:54.288317Z",
          "iopub.status.idle": "2025-08-12T05:15:54.293418Z",
          "shell.execute_reply": "2025-08-12T05:15:54.29285Z",
          "shell.execute_reply.started": "2025-08-12T05:15:54.288569Z"
        },
        "trusted": true,
        "id": "fvwdVq-h4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = start_test_set.drop(\"Exited\", axis=1)\n",
        "y_val = start_test_set[\"Exited\"].copy()\n",
        "X_val_prepared = preprocessor.transform(X_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:16:21.0519Z",
          "iopub.status.busy": "2025-08-12T05:16:21.051041Z",
          "iopub.status.idle": "2025-08-12T05:16:21.087551Z",
          "shell.execute_reply": "2025-08-12T05:16:21.086842Z",
          "shell.execute_reply.started": "2025-08-12T05:16:21.051868Z"
        },
        "trusted": true,
        "id": "flftvqKt4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Imbalance Handling\n",
        "\n",
        "- The dataset has ~80% 'Not Churned' in the target, so models may be biased toward the majority class.\n",
        "- To mitigate this, we explicitly calculate a **`scale_pos_weight`** to emphasize the minority class (Introverts) during training:\n",
        "\n",
        "**Breakdown of Class Imbalance Calculation**\n",
        "\n",
        "| Line                                   | What It Does     | Why It's Useful                      |\n",
        "| -------------------------------------- | ---------------- | ------------------------------------ |\n",
        "| `class_1 = df_train_label_new.sum()`                    | Count of class 1 | Needed for imbalance calculation     |\n",
        "| `class_0 = len(df_train_label_new) - class_1`           | Count of class 0 | Complement of class 1                |\n",
        "| `scale_pos_weight = class_0 / class_1` | Weight factor    | Penalizes minority class errors more |\n",
        "\n",
        "**Class Imbalance Strategies by Model**\n",
        "\n",
        "- We instantiate five high-performance gradient boosting models, each tuned using Optuna and configured to handle class imbalance natively.\n",
        "\n",
        "| Model                            | Class Imbalance Handling                   |\n",
        "| -------------------------------- | ------------------------------------------ |\n",
        "| `CatBoostClassifier`             | `class_weights={1: scale_pos_weight}`       |\n",
        "| `LGBMClassifier`          | `class_weight={0: 1, 1: scale_pos_weight}` |\n",
        "| `XGBClassifier`           | `scale_pos_weight=scale_pos_weight`        |\n",
        "| `HistGradientBoostingClassifier` | `class_weight=\"balanced\"`                  |\n",
        "\n",
        "- These configurations ensure that each model gives proportional attention to both personality classes."
      ],
      "metadata": {
        "id": "31ONhJ5q4-re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoostClassifier"
      ],
      "metadata": {
        "id": "6eKlD4YK4-re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_cb = {\n",
        "\"bootstrap_type\": \"Bernoulli\",\n",
        "\"colsample_bylevel\": 0.7658926065030167,\n",
        "\"iterations\": 1984,\n",
        "\"depth\": 5,\n",
        "\"learning_rate\": 0.015171349611571652,\n",
        "\"l2_leaf_reg\": 1.337578073889382,\n",
        "\"min_data_in_leaf\": 76,\n",
        "\"subsample\": 0.7280698256173038,\n",
        "\"eval_metric\": \"AUC\",\n",
        "\"class_weights\": [1, scale_pos_weight],\n",
        "\"verbose\": False,\n",
        "\"random_seed\": seed,\n",
        "\"loss_function\": \"Logloss\",\n",
        "\"allow_writing_files\": False\n",
        "}\n",
        "\n",
        "model_cb = CatBoostClassifier(**param_cb)\n",
        "model_cb"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:14:10.999938Z",
          "iopub.status.busy": "2025-08-12T05:14:10.999211Z",
          "iopub.status.idle": "2025-08-12T05:14:11.006117Z",
          "shell.execute_reply": "2025-08-12T05:14:11.00517Z",
          "shell.execute_reply.started": "2025-08-12T05:14:10.999912Z"
        },
        "trusted": true,
        "id": "Jx9JDbk_4-re"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rocScore_cat = evaluate_model(model = model_cb, X_train=df_train_new_prepared, X_val=X_val_prepared,\n",
        "                               y_train=df_train_label_new, y_val=y_val, figsize=(15, 10))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:16:42.463236Z",
          "iopub.status.busy": "2025-08-12T05:16:42.462688Z",
          "iopub.status.idle": "2025-08-12T05:17:12.697215Z",
          "shell.execute_reply": "2025-08-12T05:17:12.696575Z",
          "shell.execute_reply.started": "2025-08-12T05:16:42.46321Z"
        },
        "trusted": true,
        "id": "Y3sZZnGG4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBClassifier"
      ],
      "metadata": {
        "id": "17NAoCaz4-rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_xgb = {\n",
        "\"n_estimators\": 1637,\n",
        "\"learning_rate\": 0.013448370696239944,\n",
        "\"max_depth\": 5,\n",
        "\"min_child_weight\": 0.03159892617906292,\n",
        "\"subsample\": 0.7185805327584004,\n",
        "\"colsample_bytree\": 0.6611176553575923,\n",
        "\"gamma\": 5.256647828620208,\n",
        "\"reg_alpha\": 1.8881089265623683e-07,\n",
        "\"reg_lambda\": 3.3879565314300123e-07,\n",
        "\"n_jobs\": -1,\n",
        "\"random_state\": seed,\n",
        "\"scale_pos_weight\": scale_pos_weight,\n",
        "\"objective\": \"binary:logistic\",\n",
        "\"eval_metric\": \"auc\"\n",
        "}\n",
        "\n",
        "model_xgb = XGBClassifier(**param_xgb)\n",
        "model_xgb"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:38:20.580958Z",
          "iopub.status.busy": "2025-08-12T05:38:20.580361Z",
          "iopub.status.idle": "2025-08-12T05:38:20.589139Z",
          "shell.execute_reply": "2025-08-12T05:38:20.588501Z",
          "shell.execute_reply.started": "2025-08-12T05:38:20.580935Z"
        },
        "trusted": true,
        "id": "yhkGpW0I4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rocScore_xgb = evaluate_model(model = model_xgb, X_train=df_train_new_prepared, X_val=X_val_prepared,\n",
        "                               y_train=df_train_label_new, y_val=y_val, figsize=(15, 10))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T05:39:05.860284Z",
          "iopub.status.busy": "2025-08-12T05:39:05.859689Z",
          "iopub.status.idle": "2025-08-12T05:39:17.600736Z",
          "shell.execute_reply": "2025-08-12T05:39:17.600116Z",
          "shell.execute_reply.started": "2025-08-12T05:39:05.86026Z"
        },
        "trusted": true,
        "id": "yWxg_ZaM4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBMClassifier"
      ],
      "metadata": {
        "id": "ab_ESoKk4-rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "param_lgbm = {\n",
        "\"n_estimators\": 1530,\n",
        "\"learning_rate\": 0.0030804807162494864,\n",
        "\"num_leaves\": 345,\n",
        "\"max_depth\": 5,\n",
        "\"min_child_samples\": 62,\n",
        "\"min_split_gain\": 0.6369464169580782,\n",
        "\"feature_fraction\": 0.7846216887053435,\n",
        "\"bagging_fraction\": 0.7647361784813704,\n",
        "\"reg_alpha\": 0.3212093236745268,\n",
        "\"reg_lambda\": 0.0006563052961663804,\n",
        "\"max_bin\": 243,\n",
        "\"bagging_freq\": 7,\n",
        "\"objective\": \"binary\",\n",
        "\"metric\": \"AUC\",\n",
        "\"random_state\": seed,\n",
        "\"n_jobs\": -1,\n",
        "\"verbosity\": -1\n",
        "}\n",
        "\n",
        "model_lgbm = LGBMClassifier(**param_lgbm)\n",
        "model_lgbm"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T06:32:49.83348Z",
          "iopub.status.busy": "2025-08-12T06:32:49.832732Z",
          "iopub.status.idle": "2025-08-12T06:32:49.841128Z",
          "shell.execute_reply": "2025-08-12T06:32:49.840558Z",
          "shell.execute_reply.started": "2025-08-12T06:32:49.833458Z"
        },
        "trusted": true,
        "id": "2SUlgkQH4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rocScore_lgbm = evaluate_model(model = model_lgbm, X_train=df_train_new_prepared, X_val=X_val_prepared,\n",
        "                               y_train=df_train_label_new, y_val=y_val, figsize=(15, 10))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T06:33:10.241361Z",
          "iopub.status.busy": "2025-08-12T06:33:10.24063Z",
          "iopub.status.idle": "2025-08-12T06:33:27.877398Z",
          "shell.execute_reply": "2025-08-12T06:33:27.875991Z",
          "shell.execute_reply.started": "2025-08-12T06:33:10.241327Z"
        },
        "trusted": true,
        "id": "lp_k-GsO4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HistGradientBoostingClassifier"
      ],
      "metadata": {
        "id": "cZwx9pjR4-rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "param_hgb = {\n",
        "\"learning_rate\": 0.0323356329876002,\n",
        "\"max_iter\": max_iter,\n",
        "\"max_leaf_nodes\": 15,\n",
        "\"min_samples_leaf\": 254,\n",
        "\"l2_regularization\": 0.00011009865934208523,\n",
        "\"max_bins\": 117,\n",
        "\"early_stopping\": True,\n",
        "\"validation_fraction\": 0.1,\n",
        "\"random_state\": seed,\n",
        "\"verbose\": 0,\n",
        "\"class_weight\": \"balanced\",\n",
        "\"loss\": \"log_loss\"\n",
        "}\n",
        "\n",
        "model_hgb = HistGradientBoostingClassifier(**param_hgb)\n",
        "model_hgb"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:01:22.207635Z",
          "iopub.status.busy": "2025-08-12T07:01:22.207076Z",
          "iopub.status.idle": "2025-08-12T07:01:22.214415Z",
          "shell.execute_reply": "2025-08-12T07:01:22.21379Z",
          "shell.execute_reply.started": "2025-08-12T07:01:22.20761Z"
        },
        "trusted": true,
        "id": "BRoLUYyF4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rocScore_hgb = evaluate_model(model = model_hgb, X_train=df_train_new_prepared, X_val=X_val_prepared,\n",
        "                               y_train=df_train_label_new, y_val=y_val, figsize=(15, 10))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:01:48.996285Z",
          "iopub.status.busy": "2025-08-12T07:01:48.995714Z",
          "iopub.status.idle": "2025-08-12T07:01:55.253267Z",
          "shell.execute_reply": "2025-08-12T07:01:55.252389Z",
          "shell.execute_reply.started": "2025-08-12T07:01:48.996262Z"
        },
        "trusted": true,
        "id": "ULQCYY8-4-rf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Prepare Final Submission File</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Prepare Final Submission File\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Zc43-IYy4-rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "voting_clf_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"cb\", model_cb),\n",
        "        (\"xgb\", model_xgb),\n",
        "        (\"lgbm\", model_lgbm),\n",
        "        (\"hgb\", model_hgb)\n",
        "    ],\n",
        "    voting=\"soft\",\n",
        "    weights=[rocScore_cat, rocScore_xgb, rocScore_lgbm, rocScore_hgb],\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:05:01.572338Z",
          "iopub.status.busy": "2025-08-12T07:05:01.571751Z",
          "iopub.status.idle": "2025-08-12T07:05:01.576451Z",
          "shell.execute_reply": "2025-08-12T07:05:01.575841Z",
          "shell.execute_reply.started": "2025-08-12T07:05:01.572314Z"
        },
        "trusted": true,
        "id": "PwSM4iFq4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_prepared = preprocessor.transform(processed_test_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:05:28.604063Z",
          "iopub.status.busy": "2025-08-12T07:05:28.603776Z",
          "iopub.status.idle": "2025-08-12T07:05:28.678394Z",
          "shell.execute_reply": "2025-08-12T07:05:28.677825Z",
          "shell.execute_reply.started": "2025-08-12T07:05:28.604045Z"
        },
        "trusted": true,
        "id": "N1Jv7YHk4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rocScore_vc = evaluate_model(model = voting_clf_soft, X_train=df_train_new_prepared, X_val=X_val_prepared,\n",
        "               y_train=df_train_label_new, y_val=y_val, figsize=(15, 10))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:06:11.915104Z",
          "iopub.status.busy": "2025-08-12T07:06:11.914827Z",
          "iopub.status.idle": "2025-08-12T07:07:57.02539Z",
          "shell.execute_reply": "2025-08-12T07:07:57.024506Z",
          "shell.execute_reply.started": "2025-08-12T07:06:11.915084Z"
        },
        "trusted": true,
        "id": "zr-RNK8E4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predicted probabilities for the test set\n",
        "y_pred_test_prob_cat = voting_clf_soft.predict_proba(df_test_prepared)\n",
        "exited = y_pred_test_prob_cat[:, 1]\n",
        "\n",
        "# Prepare submission file\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": df_test.index,\n",
        "    \"Exited\": exited\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\nSubmission file saved!\")\n",
        "submission.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T07:12:32.8123Z",
          "iopub.status.busy": "2025-08-12T07:12:32.811711Z",
          "iopub.status.idle": "2025-08-12T07:12:41.424581Z",
          "shell.execute_reply": "2025-08-12T07:12:41.423566Z",
          "shell.execute_reply.started": "2025-08-12T07:12:32.812276Z"
        },
        "trusted": true,
        "id": "IuwNfmVL4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distribution of predicted probabilities\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(exited, bins=30, kde=True)\n",
        "plt.title(\"Distribution of Predicted Exited Probabilities\", weight=\"bold\")\n",
        "plt.xlabel(\"Predicted Probability of Exited\")\n",
        "sns.despine(left=False, bottom=False, right=False)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xlim(0, 1)  # Limit x-axis to [0, 1]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oMfLM05m4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "binary_predictions = (exited > 0.5).astype(int)\n",
        "\n",
        "# Plot distribution of binary predictions\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=binary_predictions.flatten(), palette= color(n_colors=2))\n",
        "plt.title(\"Distribution of Predicted Exited\", weight=\"bold\")\n",
        "plt.xlabel(\"Exited Status (0: Not churned, 1: Churned)\")\n",
        "plt.ylabel(\"\")\n",
        "sns.despine(left=False, bottom=False)\n",
        "plt.xticks(ticks=[0, 1], labels=[\"Not churned\", \"Churned\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kaClU_cd4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "shap_plot(model=voting_clf_soft, X_test=df_test_prepared[:200], list_feature=list_feature_prepared, type=\"bar\")"
      ],
      "metadata": {
        "id": "ua9JrzBu4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "shap_plot(model=voting_clf_soft, X_test=df_test_prepared[:200], list_feature=list_feature_prepared)"
      ],
      "metadata": {
        "id": "EAaoI1Kz4-rg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most important features**\n",
        "\n",
        "From top to bottom ‚Äî decreasing influence:\n",
        "\n",
        "1. **cat\\_onehot\\_\\_NumOfProducts\\_2**\n",
        "\n",
        "   * High values (red) ‚Üí negative SHAP ‚Üí reduce churn.\n",
        "   * Low values (blue, meaning the customer doesn‚Äôt have 2 products) ‚Üí positive SHAP ‚Üí increase churn.\n",
        "   * Meaning: Customers with **2 products** are less likely to leave.\n",
        "\n",
        "2. **num\\_robust\\_\\_PT\\_Age**\n",
        "\n",
        "   * Older customers (red) ‚Üí positive SHAP ‚Üí more likely to churn.\n",
        "   * Younger customers (blue) ‚Üí negative SHAP ‚Üí less likely to churn.\n",
        "   * Meaning: Older customers have a higher risk of leaving.\n",
        "\n",
        "3. **cat\\_onehot\\_\\_NumOfProducts\\_1**\n",
        "\n",
        "   * High values (red) ‚Üí positive SHAP ‚Üí increase churn.\n",
        "   * Meaning: Customers with **only 1 product** are at higher churn risk.\n",
        "\n",
        "4. **cat\\_keep\\_\\_IsActiveMember**\n",
        "\n",
        "   * Active (red) ‚Üí negative SHAP ‚Üí reduce churn.\n",
        "   * Inactive (blue) ‚Üí positive SHAP ‚Üí increase churn.\n",
        "   * Meaning: Inactive customers are more likely to leave.\n",
        "\n",
        "5. **cat\\_onehot\\_\\_Geography\\_Germany**\n",
        "\n",
        "   * Located in Germany (red) ‚Üí positive SHAP ‚Üí higher churn risk.\n",
        "   * Other locations ‚Üí different impacts."
      ],
      "metadata": {
        "id": "uJM7YWu04-rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "# <span style=\"color:transparent;\">Recommendation</span>\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #fff;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "        font-size: 36px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        Recommendation\n",
        "    </h1>\n",
        "</div>"
      ],
      "metadata": {
        "id": "TrShfo5R4-rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business insights**\n",
        "\n",
        "* **Cross-sell additional products**: Moving customers from 1 product to 2 products can reduce churn.\n",
        "* **Focus on older customer retention**: Improve experience, offer personalized perks.\n",
        "* **Increase customer activity**: Run campaigns to encourage transactions, logins, and online service usage.\n",
        "* **Monitor German customers**: Possibly due to competitive landscape or product fit ‚Äî further investigation needed.\n",
        "* **Balance** and **Credit Utilization ratio** show moderate impact but are still worth tracking."
      ],
      "metadata": {
        "id": "DnpXVpTo4-rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Include Google Fonts for a modern font -->\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "<div style=\"\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid #2e7d32;\n",
        "    padding: 20px;\n",
        "    background: linear-gradient(125deg, #1b5e20 5%, #43a047 40%, #81c784 75%, #c8e6c9 100%);\n",
        "    text-align: center;\n",
        "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
        "\">\n",
        "    <h1 style=\"\n",
        "        color: #FFFFFF;\n",
        "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 5px;\n",
        "        font-size: 28px;\n",
        "        font-family: 'Roboto', sans-serif;\n",
        "        letter-spacing: 1px;\n",
        "    \">\n",
        "        üôè Thanks for Reading! üöÄ\n",
        "    </h1>\n",
        "    <p style=\"color: #ffffff; font-size: 18px; text-align: center;\">\n",
        "        Happy Coding! üôåüòä\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "YY7LpYL64-rh"
      }
    }
  ]
}